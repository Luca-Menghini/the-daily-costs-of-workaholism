---
title: "The daily costs of workaholism"
subtitle: "Supplementary material S6: Multilevel regression modeling"
author:  "Luca Menghini, Ph.D., Cristian Balducci, Ph.D."
date: "`r Sys.Date()`"
bibliography: [packagesMod.bib]
nocite: '@*'
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    toc_depth: 6
    css: styles.css
    code_download: true
  pdf_document: default
  word_document: default
  theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br>

# Aims and content

The present document includes the analytical steps implemented to model the within-individual relationships between workaholism `WHLSM` and the focused strain outcomes (i.e., afternoon and evening blood pressure `SBP` and `DBP`, emotional exhaustion `EE`, and sleep disturbances `SD`) and the within-individual interactions between `WHLSM` and psychological detachment `PD`. The analyses are conducted on the daily diary data collected with the Qualtrics platform (Qualtrics, Seattle, WA, USA) from an heterogeneous samples of workers over two weeks, pre-processed as shown in [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html), and aggregated as shown in [Supplementary Material S4](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S4_psychometrics/S4_psychometrics-code-and-output.html).

Here, we remove all objects from the R global environment.
```{r  }
# removing all objets from the workspace
rm(list=ls())
```

The following R packages are used in this document (see [References](#ref) section):
```{r  }
# required packages
packages <- c("lme4","MuMIn","sjPlot","plyr","car","fitdistrplus","ggplot2","gridExtra","influence.ME","mediation","psych","knitr")

# generate packages references
knitr::write_bib(c(.packages(), packages),"packagesMod.bib")

# # run to install missing packages
# xfun::pkg_attach2(packages, message = FALSE); rm(list=ls())
```

<br>

# 1. Data reading

First, we read daily `diary` exported from the previous step (see [Supplementary Material S4](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S4_psychometrics/S4_psychometrics-code-and-output.html), and the model formulas with the covariates selected from [Supplementary Material S5](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S5_descriptives/S5_descriptives-code-and-output.html). Moreover, we derive the the preliminary questionnaire dataset `prelqs` from the `diary` dataset.
```{r  }
# reading data
load("DATI/diary_aggregated.RData") # daily diary data
load("DATI/mformulas.RData") # selected covariates

# deriving prelqs from diary data (only including variables from the preliminary questionnaire)
prelqs <- diary[!duplicated(diary$ID),c(1,which(colnames(diary)=="gender"):ncol(diary))]

# original sample sizes
cat("diary:",nrow(diary),"responses from",nlevels(diary$ID),"participants")
cat("prelqs:",nrow(prelqs),"responses from",nlevels(prelqs$ID),"participants")
```

<br>

# 2. Data filtering

As we [pre-registered here](https://osf.io/h9zvq), we filter the data based on participant compliance with the protocol, that is we **exclude the participants with less than 3 full days of participation** (i.e., with nonmissing response to the afternoon, evening, and morning questionnaire).
```{r  }
# filtering participants with less than 3 observations
clean <- diary[0,]
for(ID in levels(diary$ID)){ 
  if(nrow(diary[diary$ID==ID & diary$aft==1 & diary$eve==1 & diary$mor==1,]) >= 3){ 
    clean <- rbind(clean,diary[diary$ID==ID,]) }}
clean$ID <- as.factor(as.character(clean$ID)) # resetting ID levels
clean_prelqs <- prelqs[prelqs$ID %in% levels(clean$ID),] # filtering prelqs data
clean_prelqs$ID <- as.factor(as.character(clean_prelqs$ID)) # resetting ID levels
cat("diary: Excluded",nlevels(diary$ID)-nlevels(clean$ID),"participants and",nrow(diary)-nrow(clean),"observations")

# updating sample sizes
cat("diary:",nrow(clean),"responses from",nlevels(clean$ID),"participants")
cat("prelqs:",nrow(clean_prelqs),"responses from",nlevels(clean_prelqs$ID),"participants")
```

<br>

## 2.1. BP data filtering

In addition to participant compliance, we pre-registered the **exclusion of all participants reporting taking blood pressure medications `bp_drugs` or suffering from a cardiovascular dysfunction `cv_dysf` from the analyses of blood pressure**. Here, we exclude such participants showing substantially higher blood pressure (see section 3.5 of [Supplementary Material S5](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S5_descriptives/S5_descriptives-code-and-output.html)). In contrast, deviating from the pre-registration (see [Supplementary Material S7](https://osf.io/bprvg)), we do not exclude those taking psychoactive `psy_drugs` or hormonal medication `horm_drugs`, or those reporting sleep dysfunctions `sleep_dysf`, as we did not find substantial differences in their blood pressure values (see section 3.5 of [Supplementary Material S5](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S5_descriptives/S5_descriptives-code-and-output.html)). Instead, we exclude these participants as a robustness check (see section 4).
```{r  }
# filtering participants with bp_drugs or cv_dysf
cleanBP <- clean[clean$bp_drugs=="No" & clean$cv_dysf=="No",]
cleanBP$ID <- as.factor(as.character(cleanBP$ID)) # resetting ID levels
cleanBP_prelqs <- prelqs[prelqs$ID %in% levels(cleanBP$ID),] # filtering prelqs data
cleanBP_prelqs$ID <- as.factor(as.character(cleanBP_prelqs$ID)) # resetting ID levels
cat("diary: Excluded further",nlevels(clean$ID)-nlevels(cleanBP$ID),"participants and",
    nrow(clean)-nrow(cleanBP),"observations from BP analyses")

# updating sample sizes
cat("diary (BP):",nrow(cleanBP),"responses from",nlevels(cleanBP$ID),"participants")
cat("prelqs (BP):",nrow(cleanBP_prelqs),"responses from",nlevels(cleanBP_prelqs$ID),"participants")
```

<br>

## 2.2. Sleep data filtering

Finally, we also pre-registered the exclusion of all participants reporting sleep dysfunctions from the analyses of sleep disturbances. However, the number of such participants is relatively high, whereas they do not seem to show substantial differences in sleep disturbances comparing to the other participants (see section 3.5 of [Supplementary Material S5](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S5_descriptives/S5_descriptives-code-and-output.html)). Thus, deviating from the pre-registration (see [Supplementary Material S7](https://osf.io/bprvg)), we do not exclude such participants from the main analyses. Instead, we exclude them as a robustness check (see section 4.5).
```{r  }
# number of participants reporting sleep dysfunctions
summary(clean[!duplicated(clean$ID),"sleep_dysf"])
```

<br>

# 3. Multilevel modeling

Here, we specify, compare, and inspect the results of a series of multilevel models for each of the following pre-registered time-varying outcomes:

- afternoon systolic `SBP_aft` and dyastolic blood pressure `DBP_aft`

- evening systolic `SBP_eve` and dyastolic blood pressure `DBP_eve`

- emotional exhaustion `EE`

- sleep disturbances `SD`

<br>

For each outcome, we implement a hierarchical regression with the following steps:

1. `m0`: **null model** only including the sample intercept, the level-2 variability around the intercept, and the residual term

2. `m1`: including the **covariates** selected in the previous step (see [Supplementary Material S5](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S5_descriptives/S5_descriptives-code-and-output.html)), in addition to psychological detachment `PD` (i.e., only for evening and next morning outcomes), and the level-2 component of workaholism `WHLSM.cm`

3. `m2`: including the level-1 component of **workaholism** `WHLSM.mc`

4. `m3`: including the level-1 **interactions** between `WHLSM.mc` and `PD` (i.e., only for outcomes measured in the evening or the following morning).

<br>

The following packages are used to optimize the analyses:
```{r  warning=FALSE,message=FALSE}
library(lme4); library(MuMIn); library(sjPlot); library(plyr); library(car); library(fitdistrplus)
library(gridExtra); library(influence.ME)
```

<br>

## 3.1. Blood pressure

First, we analyse systolic and diastolic blood pressure. As a main confirmatory analysis, we evaluate the relationships between daily levels of state workaholism and **daily averages** of blood pressure (i.e., average of afternoon, evening, and next morning measurements). Moreover, as a supplementary pre-registered analysis (see [Supplementary Material S7](https://osf.io/bprvg)) we apply the same procedure **for each time point**, that is we analyze the relationship between workaholism and afternoon, evening, and morning blood pressure measurement, respectively. Finally, based on the results, we conduct pre-registered **exploratory mediation analyses** on time-specific blood pressure measurements.

Daily averages of systolic `SBP` and diastolic blood pressure `DBP` are predicted by concurrent state workaholism `WHLSM.mc`, in addition to trait workaholism `WHLSM.cm`, and three covariates selected from the previous step (see [Supplementary Material S5](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S5_descriptives/S5_descriptives-code-and-output.html)), namely `gender`, `age`, and body mass index `BMI`.
```{r  }
mformulas[1] # covariates selected for SBP
mformulas[2] # covariates selected for DBP
```

<br>

### 3.1.1. Afternoon BP

#### 3.1.1.1. Data preparation

First, we prepare the data for the analyses by removing all cases of missing responses in the dependent variable or any predictor or covariate (**list-wise deletion**), by centering level-2 continuous predictors on the grand mean (**grand-mean-centering**), and by centering level-1 continuous predictors on the individual mean (**person-mean-centering**).
```{r }
# list-wise deletion
cleanBP_aft <- as.data.frame(na.omit(cleanBP[,c("ID","SBP_aft","DBP_aft", # grouping and dependent variables
                                                "gender","age","BMI","WHLSM", # core predictors
                                                "WE","WC","sleep_dysf","psy_drugs","horm_drugs", # for robustness checks
                                                "confounders_aft","flagBP_aft","flagTime","careless",
                                                "position","children")])) 
cleanBP_aft$ID <- as.factor(as.character(cleanBP_aft$ID)) # resetting participant identifier levels
cat("Considering",nrow(cleanBP_aft),"complete obs from",nlevels(as.factor(as.character(cleanBP_aft$ID))),"participants")

# person-mean-centering lv-1 continuous predictors
wide <- cleanBP_aft[!duplicated(cleanBP_aft$ID),] # wide-form dataset
for(Var in c("WHLSM","WE","WC")){
  wide <- cbind(wide,aggregate(cleanBP_aft[,Var],list(cleanBP_aft$ID),mean)[,2]) # individual means
  colnames(wide)[ncol(wide)] <- paste0(Var,".cm")
  cleanBP_aft <- join(cleanBP_aft,wide[,c("ID",paste0(Var,".cm"))],by="ID",type="left") # joining to long-form df
  cleanBP_aft[,paste0(Var,".mc")] <- cleanBP_aft[,Var] - cleanBP_aft[,paste0(Var,".cm")] } # mean-centered scores

# grand-mean-centering lv-2 continuous predictors
for(Var in c("age","BMI","WHLSM.cm")){ cleanBP_aft[,paste0(Var,".gmc")] <- cleanBP_aft[,Var] - mean(wide[,Var]) }

# showing data
cleanBP_aft[1:3,] # first three rows
```

<br>

#### 3.1.1.2. Model fit  {.tabset .tabset-fade .tabset-pills}

Here, we fit the multilevel models to the selected data using the default restricted maximum likelihood estimator (REML).
```{r  }
# m0: null model
m0_SBP_aft <- lmer(SBP_aft ~ (1|ID), # only fixed and random intercept + residual term
                   data=cleanBP_aft)

# m1: covariates
m1_SBP_aft <- lmer(SBP_aft ~ gender + age.gmc + BMI.gmc + WHLSM.cm.gmc + (1|ID), # covariates
                   data=cleanBP_aft)

# m2: state workaholism
m2_SBP_aft <- lmer(SBP_aft ~ gender + age.gmc + BMI.gmc + WHLSM.cm.gmc + WHLSM.mc + (1|ID),
                   data=cleanBP_aft)
```

<br>

The same models are specified for diastolic blood pressure.
```{r  }
# m0: null model
m0_DBP_aft <- lmer(DBP_aft ~ (1|ID), # only fixed and random intercept + residual term
                   data=cleanBP_aft)

# m1: covariates
m1_DBP_aft <- lmer(DBP_aft ~ gender + age.gmc + BMI.gmc + WHLSM.cm.gmc + (1|ID), # covariates
                   data=cleanBP_aft)

# m2: state workaholism
m2_DBP_aft <- lmer(DBP_aft ~ gender + age.gmc + BMI.gmc + WHLSM.cm.gmc + WHLSM.mc + (1|ID),
                   data=cleanBP_aft)
```

From the previous chunks, we see that all models converged without problems. Here, we inspect the **diagnostics** (i.e., normality of residual and random effect distributions, homoscedasticity, and multicollinearity) of the most complex model `m2.bis`. Influential cases are analyzed in a dedicated section below.

<br>

#####  SBP_aft

Model `m2.bis` shows **some deviation from normality** especially in the lower tail of the distribution of residuals and both tails of the distribution of random effects. Particularly, **participants `S082` and `S096`** are associated with the highest extreme deviations from the distributions of both random effects, and will be removed as a robustness check (see section 4.1). Besides that, we can see that the homoscedsticity assumption holds and that none of the variance inflation factors (VIFs) shows extreme values, ruling out the risk of multicollinearity.
```{r message=FALSE,warning=FALSE,fig.width=10,fig.height=6}
# normality and homoscedasticity
p <- plot_model(m2_SBP_aft,type="diag",dot.size=1)
p[[2]] <- p[[2]]$ID
plot_grid(p,tags=TRUE,margin=c(0,0,0,0))

# participant with highest random effects (i.e., BLUPS)
re <- ranef(m2_SBP_aft)$ID
re[re$WHLSM.mc==max(re$WHLSM.mc)|re$`(Intercept)`==max(re$`(Intercept)`),]
```
```{r message=FALSE,warning=FALSE,fig.width=10,fig.height=3}
# homoscedasticity and multicollinearity
par(mfrow=c(1,2))
for(Var in c("gender")){ boxplot(resid(m2_SBP_aft) ~ cleanBP_aft[,Var],main=paste("Residuals by",Var)) }
barplot(vif(m2_SBP_aft),main="VIF Values",xlim=c(0,10),las=2,horiz=TRUE) # variance inflation factors (VIFs)
abline(v = 5, lwd = 5, lty = 2)
```

<br>

Here, we better inspect the residual distribution and the fit of models specified with alternative family distributions. We can see that none of the alternative families substantially better approximate the distribution of model residuals, with the **log-transformed** solution (i.e., normal distribution with log-transformed dependent variable) showing the best fit. Yet, it is not so better than the original model. Thus, we initially **rely on the normal distribution** and then consider the **logarithmic transformation as a robustness check** (see section 4.1).
```{r fig.width=10,fig.height=6}
# inspecting residual distribution
descdist(resid(m2_SBP_aft)) # unknown best-fit distribution
```
```{r fig.width=10,fig.height=3}
# fitting model with alternative families
models <- list(
  m2_SBP_aft,
  glmer(formula=formula(m2_SBP_aft),family=Gamma(link="log"),data=cleanBP_aft), # gamma log (doesn't converge)
  glmer(formula=formula(m2_SBP_aft),family=Gamma(link="identity"),data=cleanBP_aft), # gamma id (doesn't converge)
  glmer(formula=formula(m2_SBP_aft),family=gaussian(link="log"),data=cleanBP_aft), # log-normal (singular fit)
  lmer(formula=as.formula(paste("log(SBP_aft) ~",as.character(formula(m2_SBP_aft))[3])),data=cleanBP_aft)) # log transf

# normal Q-Q plot of model residuals
par(mfrow=c(1,5))
for(i in 1:length(models)){ 
  qqnorm(resid(models[[i]]),main=c("Norm","Gamma-log","Gamma-id","log-norm","log-transf")[i]); qqline(resid(models[[i]]))}
```

<br>

##### DBP_aft

Model `m2.bis` shows **some deviation from normality** in both tails of the distribution of residuals and random effects. Particularly, **participant `S082`** is associated with the highest extreme deviation from the distributions of both random effects, and will be removed as a robustness check (see section 4.1). Besides that, we can see that the homoscedsticity assumption holds and that none of the variance inflation factors (VIFs) shows extreme values, ruling out the risk of multicollinearity.
```{r message=FALSE,warning=FALSE,fig.width=10,fig.height=6}
# normality and homoscedasticity
p <- plot_model(m2_DBP_aft,type="diag",dot.size=1)
p[[2]] <- p[[2]]$ID
plot_grid(p,tags=TRUE,margin=c(0,0,0,0))

# participant with highest random effects (i.e., BLUPS)
re <- ranef(m2_DBP_aft)$ID
re[re$WHLSM.mc==max(re$WHLSM.mc)|re$`(Intercept)`==max(re$`(Intercept)`),]
```
```{r message=FALSE,warning=FALSE,fig.width=10,fig.height=3}
# homoscedasticity and multicollinearity
par(mfrow=c(1,2))
for(Var in c("gender")){ boxplot(resid(m2_DBP_aft) ~ cleanBP_aft[,Var],main=paste("Residuals by",Var)) }
barplot(vif(m2_DBP_aft),main="VIF Values",xlim=c(0,10),las=2,horiz=TRUE) # variance inflation factors (VIFs)
abline(v = 5, lwd = 5, lty = 2)
```

<br>

Here, we better inspect the residual distribution and the fit of models specified with alternative family distributions. We can see that some of alternative families slightly better approximate the distribution of model residuals, although not reaching convergence. The **log-transformed** solution (i.e., normal distribution with log-transformed dependent variable) shows the best fit while reaching convergence. Yet, it is not so better than the original model. Thus, we initially **rely on the normal distribution** and then consider the **logarithmic transformation as a robustness check**.
```{r fig.width=10,fig.height=6}
# inspecting residual distribution
descdist(resid(m2_DBP_aft)) # unknown best-fit distribution
```
```{r fig.width=10,fig.height=3}
# fitting model with alternative families
models <- list(
  m2_DBP_aft,
  glmer(formula=formula(m2_DBP_aft),family=Gamma(link="log"),data=cleanBP_aft), # gamma log (doesn't converge)
  glmer(formula=formula(m2_DBP_aft),family=Gamma(link="identity"),data=cleanBP_aft), # gamma id (doesn't converge)
  glmer(formula=formula(m2_DBP_aft),family=gaussian(link="log"),data=cleanBP_aft), # log-normal (singular fit)
  lmer(formula=as.formula(paste("log(SBP_aft) ~",as.character(formula(m2_DBP_aft))[3])),data=cleanBP_aft)) # log transf

# normal Q-Q plot of model residuals
par(mfrow=c(1,5))
for(i in 1:length(models)){ 
  qqnorm(resid(models[[i]]),main=c("Norm","Gamma-log","Gamma-id","log-norm","log-transf")[i]); qqline(resid(models[[i]]))}
```

<br>

#### 3.1.1.3. Results {.tabset .tabset-fade .tabset-pills}

Here, we compare the specified models based on the Akaike weight and the likelihood ratio test (with type-I error set to *p* < .05), and we inspect the results of the selected model(s). 

##### SBP_aft

We can see that the inclusion of state `WHLSM` is associated with stronger evidence and significantly higher likelihood than models including less predictors (Aw = .99, $\chi^2$(1) = 15.07, *p* < .001), with **model `m2` being selected as the best model**.
```{r }
# Akaike weight adding one model at time
Weights(AIC(m0_SBP_aft,m1_SBP_aft)) # covariates: better
Weights(AIC(m0_SBP_aft,m1_SBP_aft,m2_SBP_aft)) # state workaholism: better

# Likelihood ratio test
anova(m1_SBP_aft,m2_SBP_aft) # best model is m2
```

<br>

Here, we inspect the coefficients estimated by the selected model `m2.bis` and those estimated by more parsimonious models. We can see that state `WHLSM.mc` is positively related to `BP_aft`, whereas trait `WHLSM.cm.gmc` is not. Among the included covariates, `gender`, `age` and `BMI`, but not trait `WHLSM.cm.gmc` predict higher `SBP_aft`.
```{r fig.width=10,fig.height=4}
# regression table
tab_model(m1_SBP_aft,m2_SBP_aft,
          dv.labels=c("Covariates","State WHLSM"),
          show.icc=FALSE,show.p=FALSE,show.se=TRUE,show.r2=FALSE,show.ci=FALSE,
          collapse.se=TRUE,string.est="b (SE)",show.stat=TRUE,string.stat="t")

# plotting main effects from selected model
grid.arrange(plot_model(m2_SBP_aft,type="pred",terms="WHLSM.cm.gmc"), # trait WHLSM
             plot_model(m2_SBP_aft,type="pred",terms="WHLSM.mc"),nrow=1) # state WHLSM
```

<br>

##### DBP_aft

Results are **in line with those found for `SBP_aft`**: the inclusion of state `WHLSM` is associated with stronger evidence and significantly higher likelihood than models including less predictors (Aw = .99, $\chi^2$(1) = 13.84, *p* < .001), with **model `m2` being selected as the best model**.
```{r }
# Akaike weight adding one model at time
Weights(AIC(m0_DBP_aft,m1_DBP_aft)) # covariates: better
Weights(AIC(m0_DBP_aft,m1_DBP_aft,m2_DBP_aft)) # state workaholism: better

# Likelihood ratio test
anova(m1_DBP_aft,m2_DBP_aft) # best model is m2
```

<br>

Here, we inspect the coefficients estimated by the selected model `m2` and those estimated by the other models. **In line with the results found for `SBP_aft`**, we can see that state `WHLSM.mc` is positively related to `DBP_aft`, whereas trait `WHLSM.cm.gmc` is not. Among the included covariates, both `age` and `BMI`, but not `gender` predict higher `DBP_aft`.
```{r fig.width=10,fig.height=4}
# regression table
tab_model(m1_DBP_aft,m2_DBP_aft,
          dv.labels=c("Covariates","State WHLSM"),
          show.icc=FALSE,show.p=FALSE,show.se=TRUE,show.r2=FALSE,show.ci=FALSE,
          collapse.se=TRUE,string.est="b (SE)",show.stat=TRUE,string.stat="t")

# plotting main effects from selected model
grid.arrange(plot_model(m2_DBP_aft,type="pred",terms="WHLSM.cm.gmc"), # trait WHLSM
             plot_model(m2_DBP_aft,type="pred",terms="WHLSM.mc"),nrow=1) # state WHLSM
```

<br>

#### 3.1.1.4. Influential cases

Here, we evaluate the presence of influential cases in the selected model `m2`. Specifically, the **Cook’s distance** is considered as the main measure of individual-level (i.e., participant) influence on the estimated parameters, and it is recomputed by progressively excluding the most influential participants (i.e., based on the rule-of-thumb of 4/N) until all extreme values are removed.

##### 3.1.1.4.1. Cook's distance {.tabset .tabset-fade .tabset-pills}

###### SBP_aft

We can see that participants `S096` and `S082` are potentially influential cases. Note that these are the same participants showing the most extreme deviations from the distributions of random effects (see section 3.1.2).
```{r fig.width=3,fig.height=10,warning=FALSE,message=FALSE}
# cook's distance on the whole sample
infl <- influence(m2_SBP_aft,"ID")
plot(infl,which="cook",cutoff=4/nlevels(cleanBP_aft$ID),xlab="Cook distance",ylab="ID",sort=TRUE)

# progressively excluding participants
infl <- list(
  influence(exclude.influence(m2_SBP_aft,"ID","S082"),"ID"),
  influence(exclude.influence(m2_SBP_aft,"ID",c("S082","S096")),"ID"))
for(i in 1:length(infl)){ 
  plot(infl[[i]],which="cook",cutoff=4/(nlevels(cleanBP_aft$ID)-i),xlab="Cook distance",ylab="ID",sort=TRUE) }
```

<br>

###### DBP_aft

We can see that participant `S082` is a potentially influential case. Note that this is the same participants showing the most extreme deviations from the distributions of random effects (see section 3.1.2).
```{r fig.width=3,fig.height=10,warning=FALSE,message=FALSE}
# cook's distance on the whole sample
infl <- influence(m2_DBP_aft,"ID")
plot(infl,which="cook",cutoff=4/nlevels(cleanBP_aft$ID),xlab="Cook distance",ylab="ID",sort=TRUE)

# progressively excluding participants
infl <- list(influence(exclude.influence(m2_DBP_aft,"ID","S082"),"ID"))
for(i in 1:length(infl)){ 
  plot(infl[[i]],which="cook",cutoff=4/(nlevels(cleanBP_aft$ID)-i),xlab="Cook distance",ylab="ID",sort=TRUE) }
```

<br>

##### 3.1.1.4.2. Coefficient change {.tabset .tabset-fade .tabset-pills}

###### SBP_aft

Here, we inspect the magnitude of the changes in the estimated coefficients after the removal of potentially influential cases. We can see that the coefficients estimated by the updated model do not substantially differ from those estimated by the original model. Thus, we choose to **rely on the results obtained with the full sample**.
```{r fig.width=10,fig.height=4}
# refitting model without influential cases
m2_SBP_aft.noInfl <- update(m2_SBP_aft,data=cleanBP_aft[!cleanBP_aft$ID%in%c("S096","S082"),])

# plotting coefficients original vs. updated model
plot_models(m2_SBP_aft,m2_SBP_aft.noInfl)

# showing regression table original vs. updated model
tab_model(m2_SBP_aft,m2_SBP_aft.noInfl,dv.labels=c("Original","Updated"),show.icc=FALSE,show.p=FALSE,show.se=TRUE,
          show.r2=FALSE,collapse.se=TRUE,string.est="b (SE)",show.stat=TRUE,string.stat="t")
```

<br>

###### DBP_aft

Here, we inspect the magnitude of the changes in the estimated coefficients after the removal of potentially influential cases. We can see that the removal of the influential participant mainly affects the parameter estimated for `gender`, with men showing substantially higher `DBP_aft` than women in the updated model. Thus, since `gender` is not our main focus, we **rely on the results obtained with the full sample**.
```{r fig.width=10,fig.height=4}
# refitting model without influential cases
m2_DBP_aft.noInfl <- update(m2_SBP_aft,data=cleanBP_aft[cleanBP_aft$ID!="S082",])

# plotting coefficients original vs. updated model
plot_models(m2_DBP_aft,m2_DBP_aft.noInfl)

# showing regression table original vs. updated model
tab_model(m2_DBP_aft,m2_DBP_aft.noInfl,dv.labels=c("Original","Updated"),show.icc=FALSE,show.p=FALSE,show.se=TRUE,
          show.r2=FALSE,collapse.se=TRUE,string.est="b (SE)",show.stat=TRUE,string.stat="t")
```

<br>

### 3.1.2. Evening BP

Systolic `SBP_eve` and diastolic blood pressure `DBP_eve` recoded in the evening are predicted by concurrent state workaholism `WHLSM.mc`, by psychological detachment `PD`, trait workaholism `WHLSM.cm`, and three covariates selected from the previous step (see [Supplementary Material S5](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S5_descriptives/S5_descriptives-code-and-output.html)), namely `gender`, `age`, and `BMI`. A further potential confounder highlighted from the previous step, namely `day` (i.e., expressing the linear time trend over the study protocol), is not included at this point to get more parsimonious models and more comparable results across BP models, also considering the lack of linear temporal trends in state `WHLSM` measures (see below). Particularly, as shown in [Supplementary Material S5](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S5_descriptives/S5_descriptives-code-and-output.html), such linear trend is possibly due to measurement reactivity (i.e., increased physiological activation during the first - less familiar - blood pressure recordings), and it will be considered as a robustness check in section 4.2.
```{r fig.width=8,fig.height=2}
mformulas[3] # covariates selected for SBP_aft
mformulas[4] # covariates selected for DBP_aft

# plotting WHLSM & SBP by day
par(mfrow=c(1,3)); boxplot(SBP_eve ~ day,data=clean); boxplot(DBP_eve ~ day,data=clean); boxplot(WHLSM ~ day,data=clean)

# model weight and estimated parameter for WHLSM by time
m0 <- lmer(WHLSM ~ (1|ID),data=cleanBP)
m1 <- lmer(WHLSM ~ day + (1|ID),data=cleanBP)
Weights(AIC(m0,m1)) # Akaike weights: weaker evidence than null model
summary(m1)$coefficients # coefficient: |t| < 2
```

<br>

#### 3.1.2.1. Data preparation

First, we prepare the data for the analyses by removing all cases of missing responses in the dependent variable or any predictor or covariate (**list-wise deletion**), by centering level-2 continuous predictors on the grand mean (**grand-mean-centering**), and by centering level-1 continuous predictors on the individual mean (**person-mean-centering**).
```{r }
# list-wise deletion
cleanBP_eve <- as.data.frame(na.omit(cleanBP[,c("ID","SBP_eve","DBP_eve", # grouping and dependent variables
                                                "gender","age","BMI","WHLSM","PD", # core predictors
                                                "WE","WC","sleep_dysf","psy_drugs","horm_drugs", # for robustness checks
                                                "confounders_eve","flagBP_eve","flagTime","careless","day",
                                                "position","children")])) 
cleanBP_eve$ID <- as.factor(as.character(cleanBP_eve$ID)) # resetting participant identifier levels
cat("Considering",nrow(cleanBP_eve),"complete obs from",nlevels(as.factor(as.character(cleanBP_eve$ID))),"participants")

# person-mean-centering lv-1 continuous predictors
wide <- cleanBP_eve[!duplicated(cleanBP_eve$ID),] # wide-form dataset
for(Var in c("WHLSM","PD","WE","WC")){
  wide <- cbind(wide,aggregate(cleanBP_eve[,Var],list(cleanBP_eve$ID),mean)[,2]) # individual means
  colnames(wide)[ncol(wide)] <- paste0(Var,".cm")
  cleanBP_eve <- join(cleanBP_eve,wide[,c("ID",paste0(Var,".cm"))],by="ID",type="left") # joining to long-form df
  cleanBP_eve[,paste0(Var,".mc")] <- cleanBP_eve[,Var] - cleanBP_eve[,paste0(Var,".cm")] } # mean-centered scores

# grand-mean-centering lv-2 continuous predictors
for(Var in c("age","BMI","WHLSM.cm")){ cleanBP_eve[,paste0(Var,".gmc")] <- cleanBP_eve[,Var] - mean(wide[,Var]) }

# showing data
cleanBP_eve[1:3,] # first three rows
```

<br>

#### 3.1.2.2. Model fit  {.tabset .tabset-fade .tabset-pills}

Here, we fit the multilevel models to the selected data using the default restricted maximum likelihood estimator (REML).
```{r  }
# m0: null model
m0_SBP_eve <- lmer(SBP_eve ~ (1|ID), # only fixed and random intercept + residual term
                   data=cleanBP_eve)

# m1: covariates
m1_SBP_eve <- lmer(SBP_eve ~ gender + age.gmc + BMI.gmc + PD.mc + WHLSM.cm.gmc + (1|ID), # covariates
                       data=cleanBP_eve)

# m2: state workaholism
m2_SBP_eve <- lmer(SBP_eve ~ gender + age.gmc + BMI.gmc + PD.mc + WHLSM.cm.gmc + WHLSM.mc + (1|ID),
                   data=cleanBP_eve)

# m3: interaction
m3_SBP_eve <- lmer(SBP_eve ~ gender + age.gmc + BMI.gmc + PD.mc + WHLSM.cm.gmc + WHLSM.mc + WHLSM.mc:PD.mc + (1|ID),
                   data=cleanBP_eve)
```

<br>

The same models are specified for diastolic blood pressure.
```{r  }
# m0: null model
m0_DBP_eve <- lmer(DBP_eve ~ (1|ID), # only fixed and random intercept + residual term
                   data=cleanBP_eve)

# m1: covariates
m1_DBP_eve <- lmer(DBP_eve ~ gender + age.gmc + BMI.gmc + PD.mc + WHLSM.cm.gmc + (1|ID),
                   data=cleanBP_eve)

# m2: state workaholism
m2_DBP_eve <- lmer(DBP_eve ~ gender + age.gmc + BMI.gmc + PD.mc + WHLSM.cm.gmc + WHLSM.mc + (1|ID),
                   data=cleanBP_eve)

# m3: interactions
m3_DBP_eve <- lmer(DBP_eve ~ gender + age.gmc + BMI.gmc + PD.mc + WHLSM.cm.gmc + WHLSM.mc + WHLSM.mc:PD.mc + (1|ID),
                   data=cleanBP_eve)
```

From the previous chunks, we see that all models converged without problems. Here, we inspect the **diagnostics** (i.e., normality of residual and random effect distributions, homoscedasticity, and multicollinearity) of the most complex model `m3`. Influential cases are analyzed in a dedicated section below.

##### SBP_eve

Model `m3_SBP_eve` shows **some deviation from normality** especially in the upper tail of the distribution of residuals and both tails of the distribution of random effects. Particularly, **participant `S082`** is associated with the highest extreme deviation from the distributions of random intercepts, and will be removed as a robustness check (see section 4.1). Besides that, we can see that the homoscedsticity assumption holds and that none of the variance inflation factors (VIFs) shows extreme values, ruling out the risk of multicollinearity.
```{r message=FALSE,warning=FALSE,fig.width=10,fig.height=6}
# normality and homoscedasticity
p <- plot_model(m3_SBP_eve,type="diag",dot.size=1)
p[[2]] <- p[[2]]$ID
plot_grid(p,tags=TRUE,margin=c(0,0,0,0))

# participant with highest random effects (i.e., BLUPS)
re <- ranef(m3_SBP_eve)$ID
as.character(cleanBP_prelqs[which(re$`(Intercept)`==max(re$`(Intercept)`)),"ID"])
```
```{r message=FALSE,warning=FALSE,fig.width=10,fig.height=3}
# homoscedasticity and multicollinearity
par(mfrow=c(1,2))
for(Var in c("gender")){ boxplot(resid(m3_SBP_eve) ~ cleanBP_eve[,Var],main=paste("Residuals by",Var)) }
barplot(vif(m3_SBP_eve),main="VIF Values",xlim=c(0,10),las=2,horiz=TRUE) # variance inflation factors (VIFs)
abline(v = 5, lwd = 5, lty = 2)
```

<br>

Here, we better inspect the residual distribution and the fit of models specified with alternative family distributions. We can see that none of the alternative families substantially better approximate the distribution of model residuals, with the **log-transformed** solution (i.e., normal distribution with log-transformed dependent variable) showing the best fit. Yet, it is not so better than the original model. Thus, we initially **rely on the normal distribution** and then consider the **logarithmic transformation as a robustness check** (see section 4.1).
```{r fig.width=10,fig.height=6}
# inspecting residual distribution
descdist(resid(m3_SBP_eve)) # unknown best-fit distribution
```
```{r fig.width=10,fig.height=3}
# fitting model with alternative families
models <- list(
  m3_SBP_eve,
  glmer(formula=formula(m3_SBP_eve),family=Gamma(link="log"),data=cleanBP_eve), # gamma log (doesn't converge)
  glmer(formula=formula(m3_SBP_eve),family=Gamma(link="identity"),data=cleanBP_eve), # gamma id (doesn't converge)
  glmer(formula=formula(m3_SBP_eve),family=gaussian(link="log"),data=cleanBP_eve), # log-normal (singular fit)
  lmer(formula=as.formula(paste("log(SBP_eve) ~",as.character(formula(m3_SBP_eve))[3])),data=cleanBP_eve)) # log transf

# normal Q-Q plot of model residuals
par(mfrow=c(1,5))
for(i in 1:length(models)){ 
  qqnorm(resid(models[[i]]),main=c("Norm","Gamma-log","Gamma-id","log-norm","log-transf")[i]); qqline(resid(models[[i]]))}
```

<br>

##### DBP_eve

Model `m3_DBP_eve` shows **some deviation from normality** in both tails of the distribution of residuals and random effects. Particularly, **participant `S082`** is associated with the highest extreme deviation from the distributions of both random effects, and will be removed as a robustness check (see section 4.1). Besides that, we can see that the homoscedsticity assumption holds and that none of the variance inflation factors (VIFs) shows extreme values, ruling out the risk of multicollinearity.
```{r message=FALSE,warning=FALSE,fig.width=10,fig.height=6}
# normality and homoscedasticity
p <- plot_model(m3_DBP_eve,type="diag",dot.size=1)
p[[2]] <- p[[2]]$ID
plot_grid(p,tags=TRUE,margin=c(0,0,0,0))

# participant with highest random effects (i.e., BLUPS)
re <- ranef(m3_DBP_eve)$ID
re[re$WHLSM.mc==max(re$WHLSM.mc)|re$`(Intercept)`==max(re$`(Intercept)`),]
```
```{r message=FALSE,warning=FALSE,fig.width=10,fig.height=3}
# homoscedasticity and multicollinearity
par(mfrow=c(1,2))
for(Var in c("gender")){ boxplot(resid(m3_DBP_eve) ~ cleanBP_eve[,Var],main=paste("Residuals by",Var)) }
barplot(vif(m3_DBP_eve),main="VIF Values",xlim=c(0,10),las=2,horiz=TRUE) # variance inflation factors (VIFs)
abline(v = 5, lwd = 5, lty = 2)
```

<br>

Here, we better inspect the residual distribution and the fit of models specified with alternative family distributions. We can see that none of the alternative families better approximates the distribution of model residuals, and none of them reached convergence. Thus, we initially **rely on the normal distribution** and then consider the **gamma log as a robustness check** (i.e., the only solution that converges).
```{r fig.width=10,fig.height=6}
# inspecting residual distribution
descdist(resid(m3_DBP_eve)) # unknown best-fit distribution but close to normal
```
```{r fig.width=10,fig.height=3}
# fitting model with alternative families
models <- list(
  m3_DBP_eve,
  glmer(formula=formula(m3_DBP_eve),family=Gamma(link="log"),data=cleanBP_eve), # gamma log
  glmer(formula=formula(m3_DBP_eve),family=Gamma(link="identity"),data=cleanBP_eve), # gamma id (doesn't converge)
  glmer(formula=formula(m3_DBP_eve),family=gaussian(link="log"),data=cleanBP_eve), # log-normal (singular fit)
  lmer(formula=as.formula(paste("log(SBP_eve) ~",as.character(formula(m2_DBP_eve))[3])),data=cleanBP_eve)) # log tr (singular)

# normal Q-Q plot of model residuals
par(mfrow=c(1,5))
for(i in 1:length(models)){ 
  qqnorm(resid(models[[i]]),main=c("Norm","Gamma-log","Gamma-id","log-norm","log-transf")[i]); qqline(resid(models[[i]]))}
```

<br>

#### 3.1.2.3. Results {.tabset .tabset-fade .tabset-pills}

Here, we compare the specified models based on the Akaike weight and the likelihood ratio test (with type-I error set to *p* < .05), and we inspect the results of the selected model(s). 

##### SBP_eve

We can see that the inclusion of state `WHLSM` is not associated with stronger evidence or significant likelihood ratio compared to models including less predictors (Aw = .33, $\chi^2$(1) = 0.58, *p* = .44). Similar, the interaction does not imply stronger evidence or significant likelihood ratio (Aw = .11, $\chi^2$(1) = 0.65, *p* = .42).
```{r }
# Akaike weight adding one model at time
Weights(AIC(m0_SBP_eve,m1_SBP_eve)) # covariates: better
Weights(AIC(m0_SBP_eve,m1_SBP_eve,m2_SBP_eve)) # state workaholism: worse
Weights(AIC(m0_SBP_eve,m1_SBP_eve,m2_SBP_eve,m3_SBP_eve)) # interaction: worse

# Likelihood ratio test with m3.RDet
anova(m1_SBP_eve,m2_SBP_eve,m3_SBP_eve) # best model is m1
```

<br>

Here, we inspect the coefficients estimated by the selected model `m1.bis` and those estimated by the target models. We can see that state `WHLSM.mc` is not substantially related to `BP_eve`, similar to trait `WHLSM.cm.gmc` is not. Among the included covariates, `age`, `BMI`, and low `PD` predict higher `SBP_eve`.
```{r fig.width=5,fig.height=4}
# regression table
tab_model(m1_SBP_eve,m2_SBP_eve,m3_SBP_eve,
          dv.labels=c("Covariates","State WHLSM","Interaction"),
          show.icc=FALSE,show.p=FALSE,show.se=TRUE,show.r2=FALSE,show.ci=FALSE,
          collapse.se=TRUE,string.est="b (SE)",show.stat=TRUE,string.stat="t")

# plotting main effects from model m2
grid.arrange(plot_model(m2_SBP_eve,type="pred",terms="WHLSM.cm.gmc"), # trait WHLSM
             plot_model(m2_SBP_eve,type="pred",terms="WHLSM.mc"),nrow=1) # state WHLSM

# plotting interactions
sd(cleanBP_eve$PD.mc) # RDet: 1 SD = 1.38
plot_model(m3_SBP_eve,type="pred",terms=c("WHLSM.mc","PD.mc [-1.38,1.38]"))
```

<br>

##### DBP_eve

Results are **similar to those found for `SBP_eve`**: the inclusion of state `WHLSM` is associated with stronger evidence (Aw = .68) but not with significant likelihood ratio compared to models including less predictors ($\chi^2$(1) = 3.71, *p* = .05). Similar, the interaction does not imply stronger evidence or significant likelihood ratio (Aw = .14, $\chi^2$(1) = 0.01, *p* = .99).
```{r }
# Akaike weight adding one model at time
Weights(AIC(m0_DBP_eve,m1_DBP_eve)) # covariates: better
Weights(AIC(m0_DBP_eve,m1_DBP_eve,m2_DBP_eve)) # state workaholism: better
Weights(AIC(m0_DBP_eve,m1_DBP_eve,m2_DBP_eve,m3_DBP_eve)) # state whlsm by detachment: worse

# Likelihood ratio test with m3
anova(m1_DBP_eve,m2_DBP_eve,m3_DBP_eve) # best model is m1
```

<br>

Here, we inspect the coefficients estimated by the models specified for `DBP_eve`. We can see that state `WHLSM.mc` is not substantially related to `DBP_eve`. Among the included covariates, `age` and `BMI` predict higher `SBP_eve`.
```{r fig.width=10,fig.height=4}
# regression table
tab_model(m1_DBP_eve,m2_DBP_eve,m3_DBP_eve,
          dv.labels=c("Covariates","State WHLSM","Interaction"),
          show.icc=FALSE,show.p=FALSE,show.se=TRUE,show.r2=FALSE,show.ci=FALSE,
          collapse.se=TRUE,string.est="b (SE)",show.stat=TRUE,string.stat="t")

# plotting main effects from model m2
grid.arrange(plot_model(m2_SBP_eve,type="pred",terms="WHLSM.cm.gmc"), # trait WHLSM
             plot_model(m2_SBP_eve,type="pred",terms="WHLSM.mc"),nrow=1) # state WHLSM

# plotting interactions
sd(cleanBP_eve$PD.mc) # RDet: 1 SD = 1.38
plot_model(m3_DBP_eve,type="pred",terms=c("WHLSM.mc","PD.mc [-1.38,1.38]"))
```

<br>

#### 3.1.2.4. Influential cases

Here, we evaluate the presence of influential cases in the target model `m2`. Specifically, the **Cook’s distance** is considered as the main measure of individual-level (i.e., participant) influence on the estimated parameters, and it is recomputed by progressively excluding the most influential participants (i.e., based on the rule-of-thumb of 4/N) until all extreme values are removed.

##### 3.1.2.4.1. Cook's distance {.tabset .tabset-fade .tabset-pills}

###### SBP_eve

We can see that participants `S082` and `S096` are potentially influential cases. Note that the latter is the same participants showing the most extreme deviations from the distributions of random effects (see section 3.3.2).
```{r fig.width=3,fig.height=10}
# cook's distance on the whole sample
infl <- influence(m2_SBP_eve,"ID")
plot(infl,which="cook",cutoff=4/nlevels(cleanBP_eve$ID),xlab="Cook distance",ylab="ID",sort=TRUE)

# progressively excluding participants
infl <- list(
  influence(exclude.influence(m2_SBP_eve,"ID","S082"),"ID"),
  influence(exclude.influence(m2_SBP_eve,"ID",c("S082","S096")),"ID"))
for(i in 1:length(infl)){ 
  plot(infl[[i]],which="cook",cutoff=4/(nlevels(cleanBP_eve$ID)-i),xlab="Cook distance",ylab="ID",sort=TRUE) }
```

<br>

###### DBP_eve

We can see that participants `S082` and `S080` is a potentially influential case. Note that the former is the same participant showing the most extreme deviations from the distributions of random effects (see section 3.3.2).
```{r fig.width=3,fig.height=10,warning=FALSE,message=FALSE}
# cook's distance on the whole sample
infl <- influence(m2_DBP_eve,"ID")
plot(infl,which="cook",cutoff=4/nlevels(cleanBP_eve$ID),xlab="Cook distance",ylab="ID",sort=TRUE)

# progressively excluding participants
infl <- list(influence(exclude.influence(m2_DBP_eve,"ID","S082"),"ID"),
             influence(exclude.influence(m2_DBP_eve,"ID",c("S082","S080")),"ID"))
for(i in 1:length(infl)){ 
  plot(infl[[i]],which="cook",cutoff=4/(nlevels(cleanBP_eve$ID)-i),xlab="Cook distance",ylab="ID",sort=TRUE) }
```

<br>

##### 3.1.2.4.2. Coefficient change {.tabset .tabset-fade .tabset-pills}

###### SBP_eve

Here, we inspect the magnitude of the changes in the estimated coefficients after the removal of potentially influential cases. We can see that the coefficients estimated by the updated model do not substantially differ from those estimated by the original model. Thus, we choose to **rely on the results obtained with the full sample**.
```{r fig.width=10,fig.height=4}
# refitting model without influential cases
m2_SBP_eve.noInfl <- update(m2_SBP_eve,data=cleanBP_eve[!cleanBP_eve$ID%in%c("S082","S096"),])

# plotting coefficients original vs. updated model
plot_models(m2_SBP_eve,m2_SBP_eve.noInfl)

# same thing with interactions
m3_DBP_eve.noInfl <- update(m3_SBP_eve,data=cleanBP_eve[!cleanBP_eve$ID%in%c("S082","S096"),])
plot_models(m3_SBP_eve,m3_DBP_eve.noInfl)

# showing regression table original vs. updated model
tab_model(m2_SBP_eve,m2_SBP_eve.noInfl,dv.labels=c("Original","Updated"),show.icc=FALSE,show.p=FALSE,show.se=TRUE,
          show.r2=FALSE,collapse.se=TRUE,string.est="b (SE)",show.stat=TRUE,string.stat="t")
```

<br>

###### DBP_eve

Here, we inspect the magnitude of the changes in the estimated coefficients after the removal of potentially influential cases. We can see that the coefficient estimated for state `WHLSM.mc` by the updated model is strongly reduced. Thus, these results **question the generalizability of the estimated relationship between `WHLSM.mc` and `DBP_eve`**.
```{r fig.width=10,fig.height=4}
# refitting model without influential cases
m2_DBP_eve.noInfl <- update(m2_SBP_eve,data=cleanBP_eve[!cleanBP_eve$ID%in%c("S082","S080"),])

# plotting coefficients original vs. updated model
plot_models(m2_DBP_eve,m2_DBP_eve.noInfl)

# same thing with interaction
m3_DBP_eve.noInfl <- update(m3_SBP_eve,data=cleanBP_eve[!cleanBP_eve$ID%in%c("S082","S080"),])
plot_models(m3_DBP_eve,m3_DBP_eve.noInfl)

# showing regression table original vs. updated model
tab_model(m2_DBP_eve,m2_DBP_eve.noInfl,dv.labels=c("Original","Updated"),show.icc=FALSE,show.p=FALSE,show.se=TRUE,
          show.r2=FALSE,collapse.se=TRUE,string.est="b (SE)",show.stat=TRUE,string.stat="t")
```

<br>

### 3.1.3. Mediation {.tabset .tabset-fade .tabset-pills}

In light of the relationships found between state workaholism and afternoon blood pressure, and the substantial correlation found between afternoon and evening blood pressure, here we explore the mediating paths between workaholism and later blood pressure measurements by evaluating the potential mediating role of afternoon blood pressure. This is done by considering the same covariates included above, namely `gender`, `age`, `BMI`, `PD`, and trait `WHLSM.cm`.
```{r message=FALSE,warning=FALSE}
library(mediation) # loding mediation package
```

```{r }
# data preparation (list-wise deletion and mean centering)
cleanBP_med_eve <- as.data.frame(na.omit(cleanBP[,c("ID","SBP_aft","DBP_aft","SBP_eve","DBP_eve", # grouping and response vars
                                                "gender","age","BMI","WHLSM","PD", # core predictors
                                                "WE","WC","sleep_dysf","psy_drugs","horm_drugs", # for robustness checks
                                                "confounders_aft","confounders_eve",
                                                "flagBP_aft","flagBP_eve","flagTime","careless","day",
                                                "children","position")])) 
cleanBP_med_eve$ID <- as.factor(as.character(cleanBP_med_eve$ID)) # resetting participant identifier levels
wide <- cleanBP_med_eve[!duplicated(cleanBP_med_eve$ID),] # wide-form dataset
for(Var in c("WHLSM","PD","SBP_aft","DBP_aft","WE","WC")){
  wide <- cbind(wide,aggregate(cleanBP_med_eve[,Var],list(cleanBP_med_eve$ID),mean)[,2]) # individual means
  colnames(wide)[ncol(wide)] <- paste0(Var,".cm")
  cleanBP_med_eve <- join(cleanBP_med_eve,wide[,c("ID",paste0(Var,".cm"))],by="ID",type="left") # joining to long-form df
  cleanBP_med_eve[,paste0(Var,".mc")] <- cleanBP_med_eve[,Var] - cleanBP_med_eve[,paste0(Var,".cm")] } # mean-centered scores
for(Var in c("age","BMI","WHLSM.cm")){ cleanBP_med_eve[,paste0(Var,".gmc")] <- cleanBP_med_eve[,Var] - mean(wide[,Var]) } # gmc
cat("Considering",nrow(cleanBP_med_eve),"complete obs from",nlevels(as.factor(as.character(cleanBP_med_eve$ID))),"participants")
```

<br>

We can see that a significant indirect effect is estimated in both cases, whereas the direct effect is not significant for both systolic and diastolic blood pressure. Results are consistent after the removal of influential cases.

#### SBP_eve
```{r }
# output and mediation models
mOut_SBP_eve <- lmer(SBP_eve ~ gender + age.gmc + BMI.gmc + PD.mc + WHLSM.cm.gmc + WHLSM.mc + SBP_aft.mc + 
                       (1|ID),data=cleanBP_med_eve)
mMed_SBP_eve <- lmer(SBP_aft ~ gender + age.gmc + BMI.gmc + PD.mc + WHLSM.cm.gmc + WHLSM.mc + 
                       (1|ID),data=cleanBP_med_eve)

# mediation results
NSIM <- 10000
med_SBP_eve <- mediation::mediate(model.m=mMed_SBP_eve,model.y=mOut_SBP_eve,treat="WHLSM.mc",mediator="SBP_aft.mc",
                       covariates=cleanBP_med_eve[,c("gender","age.gmc","BMI.gmc","PD.mc","WHLSM.cm.gmc")],
                       boot=FALSE,sims=NSIM) # quasi-Bayesian CI
summary(med_SBP_eve) # significant indirect effect

# mediation results without influential cases
mOut_SBP_eve.noInfl <- update(mOut_SBP_eve,data=cleanBP_med_eve[!cleanBP_med_eve$ID%in%c("S082","S096"),])
mMed_SBP_eve.noInfl <- update(mMed_SBP_eve,data=cleanBP_med_eve[!cleanBP_med_eve$ID%in%c("S082","S096"),])
med_SBP_eve.noInfl <- mediation::mediate(model.m=mMed_SBP_eve.noInfl,model.y=mOut_SBP_eve.noInfl,
                              treat="WHLSM.mc",mediator="SBP_aft.mc",
                              covariates=cleanBP_med_eve[!cleanBP_med_eve$ID%in%c("S082","S096"),
                                                         c("gender","age.gmc","BMI.gmc","PD.mc","WHLSM.cm.gmc")],
                              boot=FALSE,sims=NSIM) # quasi-Bayesian CI
summary(med_SBP_eve.noInfl) # indirect effect stays significant
```

<br>

#### DBP_eve
```{r }
# output and mediation models
mOut_DBP_eve <- lmer(DBP_eve ~ gender + age.gmc + BMI.gmc + PD.mc + WHLSM.cm.gmc + WHLSM.mc + DBP_aft.mc + 
                       (1|ID),data=cleanBP_med_eve)
mMed_DBP_eve <- lmer(DBP_aft ~ gender + age.gmc + BMI.gmc + PD.mc + WHLSM.cm.gmc + WHLSM.mc + 
                       (1|ID),data=cleanBP_med_eve)

# mediation results
med_DBP_eve <- mediation::mediate(model.m=mMed_DBP_eve,model.y=mOut_DBP_eve,treat="WHLSM.mc",mediator="DBP_aft.mc",
                       covariates=cleanBP_med_eve[,c("gender","age.gmc","BMI.gmc","PD.mc","WHLSM.cm.gmc")],
                       boot=FALSE,sims=NSIM) # quasi-Bayesian CI
summary(med_DBP_eve) # significant indirect effect

# mediation results without influential cases
mOut_DBP_eve.noInfl <- update(mOut_DBP_eve,data=cleanBP_med_eve[!cleanBP_med_eve$ID%in%c("S082","S080"),])
mMed_DBP_eve.noInfl <- update(mMed_DBP_eve,data=cleanBP_med_eve[!cleanBP_med_eve$ID%in%c("S082","S080"),])
med_DBP_eve.noInfl <- mediation::mediate(model.m=mMed_DBP_eve.noInfl,model.y=mOut_DBP_eve.noInfl,
                              treat="WHLSM.mc",mediator="DBP_aft.mc",
                              covariates=cleanBP_med_eve[!cleanBP_med_eve$ID%in%c("S082","S080"),
                                                         c("gender","age.gmc","BMI.gmc","PD.mc","WHLSM.cm.gmc")],
                              boot=FALSE,sims=NSIM) # quasi-Bayesian CI
summary(med_DBP_eve.noInfl) # indirect effect stays significant
```

<br>

## 3.2. Emotional Exhaustion

Emotional exhaustion `EE` rated in the evening is predicted by state workaholism `WHLSM.mc`, in addition to psychological detachment `PD`, trait workaholism `WHLSM.cm`, and one covariate selected from the previous step (see [Supplementary Material S5](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S5_descriptives/S5_descriptives-code-and-output.html)), namely `gender`.
```{r  }
mformulas[5] # covariates selected for EE
```

<br>

### 3.2.1. Data preparation

First, we prepare the data for the analyses by removing all cases of missing responses in the dependent variable or any predictor or covariate (**list-wise deletion**), by centering level-2 continuous predictors on the grand mean (**grand-mean-centering**), and by centering level-1 continuous predictors on the individual mean (**person-mean-centering**).
```{r }
# list-wise deletion
cleanEE <- as.data.frame(na.omit(clean[,c("ID","EE","gender","PD","WHLSM", # core variables
                                          "WE","WC","flagTime","careless","day", # for robustness checks
                                          "position","children")])) 
cleanEE$ID <- as.factor(as.character(cleanEE$ID)) # resetting participant identifier levels
cat("Considering",nrow(cleanEE),"complete observations from",nlevels(as.factor(as.character(cleanEE$ID))),"participants")

# person-mean-centering lv-1 continuous predictors
wide <- cleanEE[!duplicated(cleanEE$ID),] # wide-form dataset
for(Var in c("PD","WHLSM","WE","WC")){
  wide <- cbind(wide,aggregate(cleanEE[,Var],list(cleanEE$ID),mean)[,2]) # computing individual means
  colnames(wide)[ncol(wide)] <- paste0(Var,".cm")
  cleanEE <- join(cleanEE,wide[,c("ID",paste0(Var,".cm"))],by="ID",type="left") # joining with long-form data
  cleanEE[,paste0(Var,".mc")] <- cleanEE[,Var] - cleanEE[,paste0(Var,".cm")] } # computing mean-centered scores

# grand-mean-centering lv-2 continuous predictors
for(Var in c("WHLSM.cm")){ cleanEE[,paste0(Var,".gmc")] <- cleanEE[,Var] - mean(wide[,Var]) }

# showing data
cleanEE[1:3,] # first three rows
```

<br>

### 3.2.2. Model fit 

Here, we fit the multilevel models to the selected data using the default restricted maximum likelihood estimator (REML).
```{r  }
# m0: null model
m0_EE <- lmer(EE ~ (1|ID), # only fixed and random intercept + residual term
              data=cleanEE)

# m1: covariates
m1_EE <- lmer(EE ~ gender + PD.mc + WHLSM.cm.gmc + (1|ID), # covariates + recovery exp
              data=cleanEE)

# m2: state workaholism
m2_EE <- lmer(EE ~ gender + PD.mc + WHLSM.cm.gmc + WHLSM.mc + (1|ID),
              data=cleanEE)

# m3: interactions
m3_EE <- lmer(EE ~ gender + PD.mc + WHLSM.cm.gmc + WHLSM.mc + WHLSM.mc + WHLSM.mc:PD.mc + (1|ID), 
              data=cleanEE)
```

From the previous chunk, we see that all models converged without problems. Here, we inspect the **diagnostics** (i.e., normality of residual and random effect distributions, homoscedasticity, and multicollinearity) of the most complex model `m3`. Influential cases are analyzed in a dedicated section below.

Model `m3` shows **some deviation from normality** in both tails of the distribution of residuals and both random effects. Besides that, we can see that the homoscedsticity assumption holds and that none of the variance inflation factors (VIFs) shows extreme values, ruling out the risk of multicollinearity.
```{r message=FALSE,warning=FALSE,fig.width=10,fig.height=6}
# normality and homoscedasticity
p <- plot_model(m3_EE,type="diag",dot.size=1) 
p[[2]] <- p[[2]]$ID
plot_grid(p,tags=TRUE,margin=c(0,0,0,0))
```
```{r message=FALSE,warning=FALSE,fig.width=10,fig.height=3}
# homoscedasticity and multicollinearity
par(mfrow=c(1,2)) 
for(Var in c("gender")){ boxplot(resid(m3_EE) ~ cleanEE[,Var],main=paste("Residuals by",Var)) }
barplot(vif(m3_EE),main="VIF Values",xlim=c(0,10),las=2,horiz=TRUE) # variance inflation factors (VIFs)
abline(v = 5, lwd = 5, lty = 2)
```

<br>

Here, we better inspect the residual distribution and the fit of models specified with alternative family distributions. We can see that alternative families might better approximate the distribution of model residuals, with the **Gamma-log** solution (i.e., Gamma distribution with logarithmic link function) showing the best fit. Yet, it is not so better than the original model. Thus, we initially **rely on the normal distribution** and then consider the **Gamma-log solution as a robustness check**.
```{r fig.width=10,fig.height=6}
# inspecting residual distribution
descdist(resid(m3_EE)) # best fit for lognormal?
```
```{r fig.width=10,fig.height=3}
# fitting model with alternative families
models <- list(
  m3_EE,
  glmer(formula=formula(m3_EE),family=Gamma(link="log"),data=cleanEE), # gamma with log
  glmer(formula=formula(m3_EE),family=Gamma(link="identity"),data=cleanEE), # [FAILS TO CONV, max|grad| = 0.09]
  glmer(formula=formula(m3_EE),family=gaussian(link="log"),data=cleanEE), # log-norm
  lmer(formula=as.formula(paste("log(EE) ~",as.character(formula(m3_EE))[3])),data=cleanEE)) # norm log

# normal Q-Q plot of model residuals
par(mfrow=c(1,5))
for(i in 1:length(models)){ 
  qqnorm(resid(models[[i]]),main=c("Norm","Gamma-log","Log-norm","log-transf")[i]); qqline(resid(models[[i]])) }
```

<br>

### 3.2.3. Results

Here, we compare the specified models based on the Akaike weight and the likelihood ratio test (with type-I error set to *p* < .05), and we inspect the results of the selected model(s). We can see that the inclusion of state `WHLSM` is associated with stronger evidence and significantly higher likelihood than the baseline model (Aw = .99, $\chi^2$(1) = 20.46, *p* < .001). In contrast, the interactive model is not better than the previous ones (Aw = .06, $\chi^2$(1) = 1.68, *p* = .19). 
```{r }
# Akaike weight adding one model at time
Weights(AIC(m0_EE,m1_EE)) # covariates: better
Weights(AIC(m0_EE,m1_EE,m2_EE)) # state workaholism: better
Weights(AIC(m0_EE,m1_EE,m2_EE,m3_EE)) # interaction: worse

# Likelihood ratio test with m3
anova(m1_EE,m2_EE,m3_EE) # best model is m2
```

<br>

Here, we inspect the coefficients estimated by the selected model `m2` and those estimated by other models. We can see that state `WHLSM.mc` is substantially and negatively related to `EE`, whereas the **interaction is not substantial**. Among the included covariates, low `PD` and high trait `WHLSM.gmc` predict substantially higher `EE`.
```{r fig.width=10,fig.height=4}
# regression table
tab_model(m1_EE,m2_EE,m3_EE,
          dv.labels=c("Baseline","State WHLSM","Interaction"),
          show.icc=FALSE,show.p=FALSE,show.se=TRUE,show.r2=FALSE,show.ci=FALSE,
          collapse.se=TRUE,string.est="b (SE)",show.stat=TRUE,string.stat="t")

# plotting main effects from selected model
grid.arrange(plot_model(m3_EE,type="pred",terms="WHLSM.cm.gmc"), # trait WHLSM
             plot_model(m3_EE,type="pred",terms="WHLSM.mc"),nrow=1) # state WHLSM

# plotting interactions
sd(cleanEE$PD.mc) # RDet: 1 SD = 1.36
plot_model(m3_EE,type="pred",terms=c("WHLSM.mc","PD.mc [-1.36,1.36]"))
```

<br>

### 3.2.4. Influential cases

Here, we evaluate the presence of influential cases in the selected model `m2.bis`. Specifically, the **Cook’s distance** is considered as the main measure of individual-level (i.e., participant) influence on the estimated parameters, and it is recomputed by progressively excluding the most influential participants (i.e., based on the rule-of-thumb of 4/N) until all extreme values are removed.

#### 3.2.4.1. Cook's distance

We can see that participant `S049` is a potentially influential case.
```{r fig.width=3,fig.height=10,warning=FALSE}
# cook's distance on the whole sample
infl <- influence(m2_EE,"ID")
plot(infl,which="cook",cutoff=4/nlevels(cleanEE$ID),xlab="Cook distance",ylab="ID",sort=TRUE)

# progressively excluding participants
infl <- influence(exclude.influence(m2_EE,"ID","S049"),"ID")
plot(infl,which="cook",cutoff=4/(nlevels(cleanEE$ID)-1),xlab="Cook distance",ylab="ID",sort=TRUE)
```

<br>

#### 3.2.4.2. Coefficient change

Here, we inspect the magnitude of the changes in the estimated coefficients after the removal of potentially influential cases. We can see that the updated models do not imply substantial changes in the estimated coefficients. Thus, we choose to **rely on the results obtained with the full sample**.
```{r fig.width=10,fig.height=4}
# refitting model without influential cases
m2_EE.noInfl <- update(m2_EE,data=cleanEE[!cleanEE$ID%in%c("S049"),])

# plotting coefficients original vs. updated model
plot_models(m2_EE,m2_EE.noInfl) # main effect
plot_models(m3_EE,update(m3_EE,data=cleanEE[!cleanEE$ID%in%c("S049"),])) # interaction

# showing regression table original vs. updated model
tab_model(m2_EE,m2_EE.noInfl,dv.labels=c("Original","Updated"),show.icc=FALSE,show.p=FALSE,show.se=TRUE,
          show.r2=FALSE,collapse.se=TRUE,string.est="b (SE)",show.stat=TRUE,string.stat="t")
```

<br>

## 3.3. Sleep disturbances

Sleep disturbances `SD` rated in the morning is predicted by previous day state workaholism `WHLSM.mc`, in addition to psychological detachment `PD`, trait workaholism `WHLSM.cm`, and one covariate selected from the previous step (see [Supplementary Material S5](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S5_descriptives/S5_descriptives-code-and-output.html)), namely `gender`.
```{r  }
mformulas[6] # covariates selected for SD
```

<br>

### 3.3.1. Data preparation

First, we prepare the data for the analyses by removing all cases of missing responses in the dependent variable or any predictor or covariate (**list-wise deletion**), by centering level-2 continuous predictors on the grand mean (**grand-mean-centering**), and by centering level-1 continuous predictors on the individual mean (**person-mean-centering**).
```{r }
# list-wise deletion
cleanSD <- as.data.frame(na.omit(clean[,c("ID","SD","gender","PD","WHLSM", # core variables
                                          "WE","WC","sleep_dysf","flagTime","careless", # for robustness checks
                                          "position","children")])) 
cleanSD$ID <- as.factor(as.character(cleanSD$ID)) # resetting participant identifier levels
cat("Considering",nrow(cleanSD),"complete observations from",nlevels(as.factor(as.character(cleanSD$ID))),"participants")

# person-mean-centering lv-1 continuous predictors
wide <- cleanSD[!duplicated(cleanSD$ID),] # wide-form dataset
for(Var in c("PD","WHLSM","WE","WC")){
  wide <- cbind(wide,aggregate(cleanSD[,Var],list(cleanSD$ID),mean)[,2]) # computing individual means
  colnames(wide)[ncol(wide)] <- paste0(Var,".cm")
  cleanSD <- join(cleanSD,wide[,c("ID",paste0(Var,".cm"))],by="ID",type="left") # joining with long-form data
  cleanSD[,paste0(Var,".mc")] <- cleanSD[,Var] - cleanSD[,paste0(Var,".cm")] } # computing mean-centered scores

# grand-mean-centering lv-2 continuous predictors
for(Var in c("WHLSM.cm")){ cleanSD[,paste0(Var,".gmc")] <- cleanSD[,Var] - mean(wide[,Var]) }

# showing data
cleanSD[1:3,] # first three rows
```

<br>

### 3.3.2. Model fit  {.tabset .tabset-fade .tabset-pills}

Here, we fit the multilevel models to the selected data using the default restricted maximum likelihood estimator (REML).
```{r  }
# m0: null model
m0_SD <- lmer(SD ~ (1|ID), # only fixed and random intercept + residual term
              data=cleanSD)

# m1: covariates
m1_SD <- lmer(SD ~ gender + PD.mc + WHLSM.cm.gmc + (1|ID), # covariates
              data=cleanSD)

# m2: state workaholism
m2_SD <- lmer(SD ~ gender + PD.mc + WHLSM.cm.gmc + WHLSM.mc + (1|ID),
              data=cleanSD)

# m3: interaction
m3_SD <- lmer(SD ~ gender + PD.mc + WHLSM.cm.gmc + WHLSM.mc + WHLSM.mc + WHLSM.mc:PD.mc + (1|ID), 
              data=cleanSD)
```

<br>

From the previous chunk, we see that all models converged without problems. Here, we inspect the **diagnostics** (i.e., normality of residual and random effect distributions, homoscedasticity, and multicollinearity) of the most complex model `m3`. Influential cases are analyzed in a dedicated section below.

Model `m3` shows **some deviation from normality** especially in the lower tail of the residual distribution and both tails of random effects, although deviation from normality is slightly less marked than in model `m2`. Besides that, we can see that the homoscedsticity assumption holds and that none of the variance inflation factors (VIFs) shows extreme values, ruling out the risk of multicollinearity.
```{r message=FALSE,warning=FALSE,fig.width=10,fig.height=6}
# normality and homoscedasticity
p <- plot_model(m3_SD,type="diag",dot.size=1) 
p[[2]] <- p[[2]]$ID
plot_grid(p,tags=TRUE,margin=c(0,0,0,0))
```
```{r message=FALSE,warning=FALSE,fig.width=10,fig.height=3}
# homoscedasticity and multicollinearity
par(mfrow=c(1,2)) 
for(Var in c("gender")){ boxplot(resid(m3_SD) ~ cleanSD[,Var],main=paste("Residuals by",Var)) }
barplot(vif(m3_SD),main="VIF Values",xlim=c(0,10),las=2,horiz=TRUE) # variance inflation factors (VIFs)
abline(v = 5, lwd = 5, lty = 2)
```

<br>

Here, we better inspect the residual distribution and the fit of models specified with alternative family distributions. We can see that alternative families might better approximate the distribution of model residuals, with the **log-normal** solution (i.e., normal distribution with logarithmic link function) showing the best fit. Yet, it is not so better than the original model. Thus, we initially **rely on the normal distribution** and then consider the **log-normal solution as a robustness check**.
```{r fig.width=10,fig.height=6}
# inspecting residual distribution
descdist(resid(m3_SD)) # best fit for Gamma
```
```{r fig.width=10,fig.height=3}
# fitting model with alternative families
models <- list(
  m3_SD,
  glmer(formula=formula(m3_SD),family=Gamma(link="log"),data=cleanSD), # Gamma with log [FAILS TO CONV, max|grad| = 0.05]
  glmer(formula=formula(m3_SD),family=Gamma(link="identity"),data=cleanSD), # Gamma with identity
  glmer(formula=formula(m3_SD),family=gaussian(link="log"),data=cleanSD), # log-norm
  lmer(formula=as.formula(paste("log(SD) ~",as.character(formula(m3_SD))[3])),data=cleanSD)) # norm log

# normal Q-Q plot of model residuals
par(mfrow=c(1,5))
for(i in 1:length(models)){ 
  qqnorm(resid(models[[i]]),main=c("Norm","Gamma-log","Log-norm","log-transf")[i]); qqline(resid(models[[i]])) }
```

<br>

### 3.3.3. Results

Here, we compare the specified models based on the Akaike weight and the likelihood ratio test (with type-I error set to *p* < .05), and we inspect the results of the selected model(s). We can see that the inclusion of both state `WHLSM` (Aw = .51, $\chi^2$(1) = 5.67, *p* = .01), and its interaction with `PD` (Aw = .21, $\chi^2$(1) = 5.68, *p* = .02) are associated with stronger evidence (not the interaction) and significantly higher likelihood than the baseline model. **Model `m3` is selected as the best model**. 
```{r }
# Akaike weight adding one model at time
Weights(AIC(m0_SD,m1_SD)) # covariates: better
Weights(AIC(m0_SD,m1_SD,m2_SD)) # state workaholism: better
Weights(AIC(m0_SD,m1_SD,m2_SD,m3_SD)) # interaction: worse

# Likelihood ratio test with m3
anova(m1_SD,m2_SD,m3_SD) # best model is m3
```

<br>

Here, we inspect the coefficients estimated by the selected model `m3` and those estimated by more parsimonious models. We can see that both trait `WHLSM.cm.gmc` and state `WHLSM.mc` are positively related to `SD`. In the selected model, a **substantial interaction** is shown such that `WHLSM.mc` is positively related to `SD` in those working days with lower `RDet` and `RRel`. Among the included covariates, `gender` predict substantial differences in `SD`, with higher sleep disturbances for females.
```{r fig.width=10,fig.height=4}
# regression table
tab_model(m1_SD,m2_SD,m3_SD,
          dv.labels=c("Baseline","State WHLSM","Interaction"),
          show.icc=FALSE,show.p=FALSE,show.se=TRUE,show.r2=FALSE,show.ci=FALSE,
          collapse.se=TRUE,string.est="b (SE)",show.stat=TRUE,string.stat="t")

# plotting main effects from selected model
grid.arrange(plot_model(m3_SD,type="pred",terms="WHLSM.cm.gmc"), # trait WHLSM
             plot_model(m3_SD,type="pred",terms="WHLSM.mc"),nrow=1) # state WHLSM

# plotting interactions
sd(cleanSD$PD.mc) # PD: 1 SD = 1.36
plot_model(m3_SD,type="pred",terms=c("WHLSM.mc","PD.mc [-1.36,1.36]"))
```

<br>

### 3.3.4. Influential cases

Here, we evaluate the presence of influential cases in the selected model `m3`. Specifically, the **Cook’s distance** is considered as the main measure of individual-level (i.e., participant) influence on the estimated parameters, and it is recomputed by progressively excluding the most influential participants (i.e., based on the rule-of-thumb of 4/N) until all extreme values are removed.

#### 3.3.4.1. Cook's distance

We can see that participants `S132`, `S049`, `S079`, and `S002` are potentially influential cases.
```{r fig.width=3,fig.height=10}
# cook's distance on the whole sample
infl <- influence(m3_SD,"ID")
plot(infl,which="cook",cutoff=4/nlevels(cleanSD$ID),xlab="Cook distance",ylab="ID",sort=TRUE)

# progressively excluding participants
infl <- list(
  influence(exclude.influence(m3_SD,"ID","S132"),"ID"),
  influence(exclude.influence(m3_SD,"ID",c("S132","S049")),"ID"),
  influence(exclude.influence(m3_SD,"ID",c("S132","S049","S079")),"ID"),
  influence(exclude.influence(m3_SD,"ID",c("S132","S049","S079","S002")),"ID"))
for(i in 1:length(infl)){ 
  plot(infl[[i]],which="cook",cutoff=4/(nlevels(cleanSD$ID)-i),xlab="Cook distance",ylab="ID",sort=TRUE) }
```

<br>

#### 3.3.4.2. Coefficient change

Here, we inspect the magnitude of the changes in the estimated coefficients after the removal of potentially influential cases. We can see that the updated model implies an increase in the coefficient estimated for trait `WHLSM.cm.gmc` and `gender`, and a decrease in those estimated for the interaction. However, it does not drop far below the cut-off of |*t*|=2. Thus, we choose to **rely on the results obtained with the full sample**.
```{r fig.width=10,fig.height=4}
# refitting model without influential cases
m3_SD.noInfl <- update(m3_SD,data=cleanSD[!cleanSD$ID%in%c("S132","S049","S079","S002"),])

# plotting coefficients original vs. updated model
plot_models(m3_SD,m3_SD.noInfl)

# showing regression table original vs. updated model
tab_model(m3_SD,m3_SD.noInfl,dv.labels=c("Original","Updated"),show.icc=FALSE,show.p=FALSE,show.se=TRUE,
          show.r2=FALSE,collapse.se=TRUE,string.est="b (SE)",show.stat=TRUE,string.stat="t")
```

<br>

# 4. Robusness checks

Here, we conduct a series of robustness checks (or *multiverse data analysis*; see [Steegen et al. 2016](#ref)) for each selected model by using alternative inclusion criteria, models with additional or less covariates, outlier removal, etc. The following packages and functions are used to optimize the analyses.

```{r warning=FALSE,message=FALSE}
library(psych)
```

<details><summary>`glmerAn`</summary>
<p>
```{r }
#' @title Generalized linear (mixed-effects) regression analysis
#' @param modelType = type of model: GLM, mixed-effects (GLMER), or cumulative link mixedm odel (CLMM)
#' @param data = data.frame of data
#' @param resp = name of the response variable (character)
#' @param fix.eff = character vector of names of the predictor(s)
#' @param REML = argument from the lme4::lmer() function, see ?lmer
#' @param ran.eff = character string indicating the random effect by using the lme4 syntax (defult: "(1|ID)")
#' @param family = character string indicating the name of the GLM(ER) family to be used in the models (default: "normal")
#' @param link =character string indicating the name of the GLM(ER) link function to be used in the models (default: "identity")
#' @param nAGQ = argument from the lme4::glmer() function, see ?glmer
#' @param mComp.baseline = character string indicating the name of the last predictor included in the baseline model to be compared with the subsequent models. If equal to NA (defult), the null model is used as the baseline model for comparison
#' @param p.adjust.method = argument from the stats::p.adjust() function (see ?p.adjust) indicating which method should be used to correct the p-values obtained from the likelihood ratio test (default: NA, for no adjustment)
#' @param key.model = character string indicating the name of the predictor(s) whose model(s) should be considered for the "key.res" output
#' @param key.predictor = character string indicating the name of the predictor to be considered by the "key.res" output
#' @param digits = number of digits for all numeric ouputs
#' @param messages = boolean indicating whether a message should be printed for each operation (defult: FALSE)
glmerAn <- function(data,modelType=c("GLMER"),resp,fix.eff,REML=TRUE,ran.eff="(1|ID)",family="normal",
                    link="identity",nAGQ=1,mComp.baseline=NA,p.adjust.method=NA,coeff.models=NA,transform=NULL,
                    plot.model=NA,plot.pred="all",key.model=NA,key.predictor=NA,digits=3,messages=FALSE){ 
  
  if(messages==TRUE){ cat("Running",modelType,"analysis of",resp,"...") }
  
  # modeling .......................................................................................
  
  # creating model formulas
  formulas <- character()
  if(modelType=="GLM"){ ran.eff <- "1" }
  null.f <- paste(resp,"~",ran.eff) # creating null model formula
  for(i in 1:length(fix.eff)){ # creating other formulas
    if(i==1){ formulas[i] <- paste(resp,"~",fix.eff[1]) } else { formulas[i] <- paste(formulas[i-1],"+",fix.eff[i])  }}
  if(modelType%in%c("GLMER","CLMM")){ if(!is.na(ran.eff)){ formulas <- paste(formulas,"+",ran.eff)
      if(substr(ran.eff,2,2)!="1"){ ranSlope <- paste(fix.eff[which(grepl(ran.eff,fix.eff))])[1]
        null.f <- gsub(ranSlope,"1",null.f)  # removing random slope from models without the related predictor
        for(i in 1:length(formulas)){ 
          if(!(grepl(ranSlope,gsub(paste(ranSlope,"[|]",sep=""),"",formulas[i])))){ 
            formulas[i] <- gsub(paste(ranSlope,"[|]",sep=""),"1|",formulas[i]) }}}
    } else { stop(message="Error: GLMER model type without ran.eff specification") }}
  if(messages==TRUE){ cat("\n\nModel specification:\n - model M0 (null):",null.f)
    for(i in 1:length(formulas)){ cat("\n - model M",i,": ",formulas[i],sep="")}}
  
  # fitting models
  models <- list()
  if(modelType=="GLM"){ if(messages==TRUE){ 
    cat("\n\nFitting GLM models of",resp,"on",nrow(data),"participants \n   using the",
        family,"family with the",link,"link function...") }
    if(family=="normal" & link=="identity"){ null.m <- lm(as.formula(null.f),data=data) # normal family
      for(i in 1:length(formulas)){ models[[i]] <- lm(formula=as.formula(formulas[i]),data=data) }
      } else if (family=="gamma") { null.m <- glm(as.formula(null.f),data=data,family=Gamma(link=link),nAGQ=nAGQ) # gamma
        for(i in 1:length(formulas)){ models[[i]] <- glm(formula=as.formula(formulas[i]),data=data,family=Gamma(link=link)) }
        } else if(family=="normal" & link!="identity"){  
          null.m <- glm(as.formula(null.f),data=data,family=gaussian(link=link)) # normal with other link functions
          for(i in 1:length(formulas)){ 
            models[[i]] <- glm(formula=as.formula(formulas[i]),data=data,family=gaussian(link=link)) }
        } else if(family=="binomial"){ 
          null.m <- glm(as.formula(null.f),data=data,family=binomial(link=link)) # logistic regression
          for(i in 1:length(formulas)){ 
            models[[i]] <- glm(formula=as.formula(formulas[i]),data=data,family=binomial(link=link))}
        } else { stop(message="Error: only normal, gamma, and binomial family are allowed, 
                      with identity, inverse, and log link functions") }
  } else if(modelType=="GLMER"){ suppressMessages(suppressWarnings(require(lme4)))
    if(messages==TRUE){ cat("\n\nFitting",modelType,"models of",resp,"on",nrow(data),"observations from",
                            nlevels(as.factor(as.character(data$ID))),"participants \n   using the",family,
                            "family with the",link,"link function using",ifelse(REML==FALSE,"ML","REML"),"estimator...") }
    if(family=="normal" & link=="identity"){ null.m <- lmer(as.formula(null.f),data=data,REML=REML) # normal  identity
      for(i in 1:length(formulas)){ models[[i]] <- lmer(formula=as.formula(formulas[i]),data=data,REML=REML) }
      } else if (family=="gamma") { null.m <- glmer(as.formula(null.f),data=data,family=Gamma(link=link),nAGQ=nAGQ) # gamma
        for(i in 1:length(formulas)){
          models[[i]]<-glmer(formula=as.formula(formulas[i]),data=data,family=Gamma(link=link),nAGQ=nAGQ) }
        } else if(family=="normal" & link!="identity"){ 
          null.m <- glmer(as.formula(null.f),data=data,family=gaussian(link=link),nAGQ=nAGQ) # normal with other links
          for(i in 1:length(formulas)){ models[[i]] <- glmer(formula=as.formula(formulas[i]),data=data,
                                                             family=gaussian(link=link),nAGQ=nAGQ) }
        } else if(family=="binomial"){ 
          null.m <- glmer(as.formula(null.f),data=data,family=binomial(link=link),nAGQ=nAGQ) # logistic
          for(i in 1:length(formulas)){ models[[i]] <- glmer(formula=as.formula(formulas[i]),data=data,
                                                             family=binomial(link=link),nAGQ=nAGQ)}
        } else { stop(message="Error: only normal, logistic, and gamma family are allowed, 
                               with identity, inverse, and log link functions") }
  } else if(modelType=="CLMM"){ suppressMessages(suppressWarnings(require(ordinal))) # cumulative link mixed models
    if(messages==TRUE){ 
      cat("\n\nFitting",modelType,"models of",resp,"on",nrow(data),"observations from",
          nlevels(as.factor(as.character(data$ID))),"participants \n   using Cumulative Link Mixed Models") }
    data[,resp] <- factor(data[,resp],ordered=TRUE) # response variable as ordered factor
    null.m <- suppressWarnings(clmm(as.formula(gsub("~","~ 1 +",null.f)),data=data)) # suppress formula warning (bugged)
    for(i in 1:length(formulas)){ models[[i]] <- suppressWarnings(clmm(formula=as.formula(formulas[i]),data=data,nAGQ=nAGQ)) }
  } else { stop(message="Error: modelType can only be 'GLM', 'GLMER', or 'CLMM'") }
  
  # outputs...............................................................................................................
  if(messages==TRUE){ cat("\n\nGenerating models outputs...") }
  
  # model comparison
    # likelihood ratio test
    if(messages==TRUE){ cat("\n\n - Running likelihood ratio test:") } 
    suppressMessages(suppressWarnings(require(knitr))); suppressMessages(suppressWarnings(require(MuMIn))) 
    m.num <- 1
    if(is.na(mComp.baseline)){ bsl <- null.m  # selecting baseline model
      } else { m.num <- grep(mComp.baseline,fix.eff)[1] + 1
         bsl <- models[[m.num - 1]] }
    if(modelType!="CLMM"){ lrt <- as.data.frame(anova(bsl,models[[m.num]]))
      if(length(models)>m.num){
        for(i in m.num:(length(models)-1)){ lrt <- rbind(lrt,as.data.frame(anova(models[[i]],models[[i+1]]))[2,]) }}
      } else { lrt <- as.data.frame(ordinal:::anova.clm(bsl,models[[m.num]])) # use anova.clm() to avoid env. issue
        if(length(models)>m.num){
          for(i in m.num:(length(models)-1)){ 
            lrt <- rbind(lrt,as.data.frame(ordinal:::anova.clm(models[[i]],models[[i+1]]))[2,]) }}}
    rownames(lrt) <- c(ifelse(is.na(mComp.baseline),"Null model","Baseline"),
                       fix.eff[m.num:length(fix.eff)])
    if(!is.na(p.adjust.method)){ # p-value corrections for multiple comparison
      if(messages==TRUE){ cat(" (applying",p.adjust.method,"p-values correction)")}
      lrt[!is.na(lrt$`Pr(>Chisq)`),"Pr(>Chisq)"] <- p.adjust(lrt[!is.na(lrt$`Pr(>Chisq)`),"Pr(>Chisq)"],
                                                             method=p.adjust.method)  }
    
    # Akaike weights
    AICs <- lrt[1:2,"AIC"] # Akaike weight
    
    # updating key results
    key <- lrt[which(grepl(key.predictor,row.names(lrt))),] # key results
    if(nrow(key)>1){ key <- key[1,] }
    key.results <- data.frame(sig.LRT=key[,ncol(key)]<0.05, # sig.LRT
                              higher.Aw=key$AIC==min(AICs[1:which(AICs==key$AIC)])) # higher.Aw
  
  # estimated parameters from key.model
  modSummary <- summary(models[[which(fix.eff==key.model)]])
  modSummary <- modSummary$coefficients
  if(modelType=="CLMM"){ modSummary <- modSummary[nlevels(data[,resp]):nrow(modSummary),] }
  key <- round(modSummary[which(grepl(key.predictor,row.names(modSummary))),3][1],2) # taking only first coeff for key.results
  key.results <- cbind(key.results,t.196=abs(key)>1.96,t=key)
  
  # returning key results (sig. LRT, Aw higher than previous model, t > 1.96)
  return(key.results) }
```
</p></details>

<details><summary>`glmerMed`</summary>
<p>
```{r }
#' @title Generalized linear mixed-effects mediation analysis
#' @param data = data.frame of data
#' @param resp = name of the response variable (character)
#' @param treat = name of the treatment variable (character)
#' @param med = name of the mediator variable (character)
#' @param fix.eff = character vector of names of the predictor(s)
#' @param REML = argument from the lme4::lmer() function, see ?lmer
#' @param ran.eff = character string indicating the random effect by using the lme4 syntax (defult: "(1|ID)")
#' @param family = character string indicating the name of the GLM(ER) family to be used in the models (default: "normal")
#' @param link = character string indicating the name of the GLM(ER) link function to be used in the models (default: "identity")
#' @param sims = number of Monte Carlo draws for quasi-Bayesian CI and p-value (default: 1000)
#' @param alpha.level = significance level (default: 0.05)
#' @param noCov = boolean indicating wheter covariates should be considered in the mediation models or not
#' @param messages = boolean indicating whether a message should be printed for each operation (defult: FALSE)
glmerMed <- function(data,resp,treat,med,fix.eff,REML=TRUE,ran.eff="(1|ID)",family="normal",
                     link="identity",sims=1000,alpha.level=0.05,noCov=FALSE,messages=FALSE){ 
  
  library(lme4); library(mediation)
  
  if(messages==TRUE){ cat("Running",modelType,"analysis of",resp,"...") }
  
  # modeling .......................................................................................
  
  # creating model formulas
  mMed.f <- paste(gsub(".mc","",med),"~",fix.eff[1])
  if(length(fix.eff)>1){
    for(i in 2:length(fix.eff)){ mMed.f <- paste(mMed.f,fix.eff[i],sep=" + ") }} # mediator model 
  mOut.f <- paste(gsub(gsub(".mc","",med),resp,mMed.f),med,sep=" + ") # outcome model
  mMed.f <- paste(mMed.f,ran.eff,sep=" + ") # adding random effects
  mOut.f <- paste(mOut.f,ran.eff,sep=" + ")
  
  # fitting models
  if(messages==TRUE){ cat("\n\nFitting GLMR models of",resp,"and",med,"on",nrow(data),"observations from",
                            nlevels(as.factor(as.character(data$ID))),"participants \n   using the",family,
                            "family with the",link,"link function using",ifelse(REML==FALSE,"ML","REML"),"estimator...") }
  if(family=="normal" & link=="identity"){ 
    mMed <- lmer(as.formula(mMed.f),data=data,REML=REML)
    mOut <- lmer(as.formula(mOut.f),data=data,REML=REML)
  } else if(family=="normal" & link!="identity") { 
      mMed <- glmer(as.formula(mMed.f),data=data,REML=REML,family=gaussian(link=link)) 
      mOut <- glmer(as.formula(mOut.f),data=data,REML=REML,family=gaussian(link=link)) 
  } else if(family=="gamma"){
      mMed <- glmer(as.formula(mMed.f),data=data,family=Gamma(link=link)) 
      mOut <- glmer(as.formula(mOut.f),data=data,family=Gamma(link=link))  
  } else { stop(message="Error: only normal, logistic, and gamma family are allowed, 
                               with identity, inverse, and log link functions") }
  
  # mediation analysis
  if(noCov==TRUE){
     medM <- mediation::mediate(model.m=mMed,model.y=mOut,treat=treat,mediator=med, # mediation & output models, treatment & mediator
                 covariates=NULL,boot=FALSE,sims=sims) # quasi-Bayesian confidence intervals
  } else {
    medM <- mediation::mediate(model.m=mMed,model.y=mOut,treat=treat,mediator=med, # mediation & output models, treatment & mediator
                 covariates=data[,fix.eff[fix.eff!=treat]], # covariates
                 boot=FALSE,sims=sims) } # quasi-Bayesian confidence intervals
  
  # returning estimated quasi-Bayesian p-value
  key.results <- data.frame(indirect.p=medM$d.avg.p,ind.p.sig=medM$d.avg.p<alpha.level,
                            direct.p=medM$z.avg.p,ind.p.sig=medM$z.avg.p<alpha.level)
  return(key.results) }
```
</p></details>

<br>

Moreover, since a further robustness check to be implemented for all outcomes is reproducing the analyses with the full sample, we also reprocess the **full `diary` dataset** by removing missing responses and mean-centering predictors.

<details><summary>Show code</summary>
<p>
```{r }
# afternoon blood pressure
cleanBP_aft_full <- as.data.frame(na.omit(diary[,c("ID","SBP_aft","DBP_aft","gender","age","BMI","WHLSM")])) # listwise del
                                                   
cleanBP_aft_full$ID <- as.factor(as.character(cleanBP_aft_full$ID)) # resetting participant identifier levels
cat(nrow(cleanBP_aft_full),"complete obs from",nlevels(as.factor(as.character(cleanBP_aft_full$ID))),"participants")
for(Var in c("WHLSM")){ # person-mean-centering lv-1 continuous predictors
  cleanBP_aft_prelqs_full <- cbind(prelqs[prelqs$ID%in%levels(cleanBP_aft_full$ID),],
                             aggregate(cleanBP_aft_full[,Var],list(cleanBP_aft_full$ID),mean)[,2]) # individual means
  colnames(cleanBP_aft_prelqs_full)[ncol(cleanBP_aft_prelqs_full)] <- paste0(Var,".cm")
  cleanBP_aft_full <- join(cleanBP_aft_full,cleanBP_aft_prelqs_full[,c("ID",paste0(Var,".cm"))],by="ID",type="left")
  cleanBP_aft_full[,paste0(Var,".mc")] <- cleanBP_aft_full[,Var] - cleanBP_aft_full[,paste0(Var,".cm")] } # mean-centered
for(Var in c("age","BMI","WHLSM.cm")){ 
  cleanBP_aft_full[,paste0(Var,".gmc")] <- cleanBP_aft_full[,Var] - mean(cleanBP_aft_prelqs_full[,Var]) } # gmc

# evening blood pressure
cleanBP_eve_full <- as.data.frame(na.omit(diary[,c("ID","SBP_eve","DBP_eve","gender","age","BMI", # list-wise deletion
                                                   "WHLSM","PD")]))
cleanBP_eve_full$ID <- as.factor(as.character(cleanBP_eve_full$ID)) # resetting participant identifier levels
cat(nrow(cleanBP_eve_full),"complete obs from",nlevels(as.factor(as.character(cleanBP_eve_full$ID))),"participants")
for(Var in c("WHLSM","PD")){ # person-mean-centering lv-1 continuous predictors
  cleanBP_eve_prelqs_full <- cbind(prelqs[prelqs$ID%in%levels(cleanBP_eve_full$ID),],
                             aggregate(cleanBP_eve_full[,Var],list(cleanBP_eve_full$ID),mean)[,2]) # individual means
  colnames(cleanBP_eve_prelqs_full)[ncol(cleanBP_eve_prelqs_full)] <- paste0(Var,".cm")
  cleanBP_eve_full <- join(cleanBP_eve_full,cleanBP_eve_prelqs_full[,c("ID",paste0(Var,".cm"))],by="ID",type="left")
  cleanBP_eve_full[,paste0(Var,".mc")] <- cleanBP_eve_full[,Var] - cleanBP_eve_full[,paste0(Var,".cm")] } # mean-centered
for(Var in c("age","BMI","WHLSM.cm")){ 
  cleanBP_eve_full[,paste0(Var,".gmc")] <- cleanBP_eve_full[,Var] - mean(cleanBP_eve[!duplicated(cleanBP_eve$ID),Var]) } # gmc

# afternoon-to-evening blood pressure
cleanBP_med_eve_full <- as.data.frame(na.omit(diary[,c("ID","SBP_aft","DBP_aft","SBP_eve","DBP_eve", # list-wise deletion
                                                       "gender","age","BMI","WHLSM","PD")])) 
cleanBP_med_eve_full$ID <- as.factor(as.character(cleanBP_med_eve_full$ID)) 
wide <- cleanBP_med_eve_full[!duplicated(cleanBP_med_eve_full$ID),] 
for(Var in c("WHLSM","PD","SBP_aft","DBP_aft")){
  wide <- cbind(wide,aggregate(cleanBP_med_eve_full[,Var],list(cleanBP_med_eve_full$ID),mean)[,2]) 
  colnames(wide)[ncol(wide)] <- paste0(Var,".cm")
  cleanBP_med_eve_full <- join(cleanBP_med_eve_full,wide[,c("ID",paste0(Var,".cm"))],by="ID",type="left") 
  cleanBP_med_eve_full[,paste0(Var,".mc")] <- cleanBP_med_eve_full[,Var] - cleanBP_med_eve_full[,paste0(Var,".cm")] } 
for(Var in c("age","BMI","WHLSM.cm")){ cleanBP_med_eve_full[,paste0(Var,".gmc")] <- 
  cleanBP_med_eve_full[,Var] - mean(wide[,Var]) } # gmc
cat("Considering",nrow(cleanBP_med_eve_full),"complete obs from",
    nlevels(as.factor(as.character(cleanBP_med_eve_full$ID))),"participants")

# emotional exhaustion
cleanEE_full <- as.data.frame(na.omit(diary[,c("ID","EE","gender","PD","WHLSM")])) # listwise deletion
cleanEE_full$ID <- as.factor(as.character(cleanEE_full$ID)) # resetting participant identifier levels
cat(nrow(cleanEE_full),"complete obs from",nlevels(as.factor(as.character(cleanEE_full$ID))),"participants")
for(Var in c("PD","WHLSM")){ # person-mean-centering lv-1 continuous predictors
  clean_prelqs_full <- cbind(prelqs[prelqs$ID%in%levels(cleanEE_full$ID),],
                             aggregate(cleanEE_full[,Var],list(cleanEE_full$ID),mean)[,2]) # individual means
  colnames(clean_prelqs_full)[ncol(clean_prelqs_full)] <- paste0(Var,".cm")
  cleanEE_full <- join(cleanEE_full,clean_prelqs_full[,c("ID",paste0(Var,".cm"))],by="ID",type="left")
  cleanEE_full[,paste0(Var,".mc")] <- cleanEE_full[,Var] - cleanEE_full[,paste0(Var,".cm")] } # mean-centered scores
for(Var in c("WHLSM.cm")){ cleanEE_full[,paste0(Var,".gmc")] <- cleanEE_full[,Var] - mean(cleanEE_full[,Var]) } # gmc

# sleep disturbances
cleanSD_full <- as.data.frame(na.omit(diary[,c("ID","SD","gender","dailyHassles_eve","PD","WHLSM")])) # listwise del
cleanSD_full$ID <- as.factor(as.character(cleanSD_full$ID)) # resetting participant identifier levels
cat(nrow(cleanSD_full),"complete obs from",nlevels(as.factor(as.character(cleanSD_full$ID))),"participants")
for(Var in c("PD","WHLSM")){ # person-mean-centering lv-1 continuous predictors
  clean_prelqs_full <- cbind(prelqs[prelqs$ID%in%levels(cleanSD_full$ID),],
                             aggregate(cleanSD_full[,Var],list(cleanSD_full$ID),mean)[,2]) # individual means
  colnames(clean_prelqs_full)[ncol(clean_prelqs_full)] <- paste0(Var,".cm")
  cleanSD_full <- join(cleanSD_full,clean_prelqs_full[,c("ID",paste0(Var,".cm"))],by="ID",type="left")
  cleanSD_full[,paste0(Var,".mc")] <- cleanSD_full[,Var] - cleanSD_full[,paste0(Var,".cm")] } # mean-centered scores
for(Var in c("WHLSM.cm")){ cleanSD_full[,paste0(Var,".gmc")] <- cleanSD_full[,Var] - mean(cleanSD_full[,Var]) } # gmc
```
</p></details>

<br>

As a further check, we include `position` as an additional covariate, which we recode into two levels, namely "Employee/Project" vs. "Managers/Employers".
```{r }
cleanBP_aft$position <- as.factor(gsub("Employee","employee/project",
                                       gsub("Project","employee/project",cleanBP_aft$position)))
cleanBP_eve$position <- as.factor(gsub("Employee","employee/project",
                                       gsub("Project","employee/project",cleanBP_eve$position)))
cleanBP_med_eve$position <- as.factor(gsub("Employee","employee/project",
                                       gsub("Project","employee/project",cleanBP_med_eve$position)))
cleanEE$position <- as.factor(gsub("Employee","employee/project",
                                       gsub("Project","employee/project",cleanEE$position)))
cleanSD$position <- as.factor(gsub("Employee","employee/project",
                                       gsub("Project","employee/project",cleanSD$position)))
```

<br>

Finally, we load the raw preliminary questionnaire item scores to compute the composite score at the retrospective version of the DUWAS, used for a robustness check.
```{r }
# isolating raw item scores at the retrospective DUWAS scale
prelqs.retroWHLSM <- prelqs[,c("ID",paste0("duwas",1:10))]
prelqs.retroWHLSM <- prelqs.retroWHLSM[prelqs.retroWHLSM$ID %in% clean$ID,] # subsampling participants included in the clean dataset
prelqs.retroWHLSM$ID <- as.factor(as.character(prelqs.retroWHLSM$ID))
cat("Included participants =",nlevels(prelqs.retroWHLSM$ID))

# computing Cronbach's alpha and 95% CI
psych::alpha(prelqs.retroWHLSM[,paste0("duwas",1:10)])$feldt

# computing grand-mean-centered composite score and adding it to all datasets used below
prelqs.retroWHLSM$WHLSM.retro <- apply(prelqs.retroWHLSM[,paste0("duwas",1:10)],1,mean)
cleanBP_aft <- plyr::join(cleanBP_aft,prelqs.retroWHLSM[,c("ID","WHLSM.retro")],by="ID",type="left")
cleanBP_aft$WHLSM.retro.gmc <- cleanBP_aft$WHLSM.retro - mean(cleanBP_aft$WHLSM.retro)
cleanBP_eve <- plyr::join(cleanBP_eve,prelqs.retroWHLSM[,c("ID","WHLSM.retro")],by="ID",type="left")
cleanBP_eve$WHLSM.retro.gmc <- cleanBP_eve$WHLSM.retro - mean(cleanBP_eve$WHLSM.retro)
cleanBP_med_eve <- plyr::join(cleanBP_med_eve,prelqs.retroWHLSM[,c("ID","WHLSM.retro")],by="ID",type="left")
cleanBP_med_eve$WHLSM.retro.gmc <- cleanBP_med_eve$WHLSM.retro - mean(cleanBP_med_eve$WHLSM.retro)
cleanEE <- plyr::join(cleanEE,prelqs.retroWHLSM[,c("ID","WHLSM.retro")],by="ID",type="left")
cleanEE$WHLSM.retro.gmc <- cleanEE$WHLSM.retro - mean(cleanEE$WHLSM.retro)
cleanSD <- plyr::join(cleanSD,prelqs.retroWHLSM[,c("ID","WHLSM.retro")],by="ID",type="left")
cleanSD$WHLSM.retro.gmc <- cleanSD$WHLSM.retro - mean(cleanSD$WHLSM.retro)
```

<br>

## 4.1. Blood pressure

### 4.1.1. Afternoon BP {.tabset .tabset-fade .tabset-pills}

For afternoon blood pressure, we implement the following robustness checks:

1. `No Infl`: we remove influential participants

2. `No dysf/drugs`: we remove all participants reporting sleep dysfunctions, hormonal or psychoactive medications, in addition to those meeting exclusion criteria for blood pressure

3. `No Cov`: we remove all covariates, that is we only include `WHLSM.mc` and its interactions as model predictors

4. `All in`: we include all complete observations from all participants, including those meeting the exclusion criteria for compliance and blood pressure

5. `ML`: we refit the models by using the Maximum Likelihood estimator, rather than the Restricted Maximum Likelihood

6. `Rand slope`: we include the random slope for `WHLSM.mc` 

7. `logTransf`: we log-transform the response variable values before fitting the models

8. `confounders_aft`: we include potentially confounding factors for blood pressure (e.g., smoking, physical activity) reported in the afternoon as an additional control variable

9. `position`: we include job position (Employee/Project vs. Manager/(Self-)Employer) as an additional control variable

10. `children`: we include the number of children as an additional control variable

9. `No flagBP`: we exclude all observations that were reprocessed due to extreme BP values (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html))

11. `No flagTime`: we exclude all observations that were flagged due to their associated timing (e.g., morning BP recorded in the afternoon) (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html))

12. `No careless`: we exclude one participant `S137` flagged as potentially careless (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html)).

13. `WE`: we replace the predictor term for state workaholism with the composite score at the working excessively dimension

14. `WC`: we replace the predictor term for state workaholism with the composite score at the working excessively dimension

15. `WHLSM retro`: we replace the predictor term for trait workaholism with the composite score at the retrospective version of the DUWAS included in the preliminary questionnaire.

<br>

In all cases, the **results are consistent** with those reported in the main analyses, showing substantial contribution and main effect of state `WHLSM.mc`.

#### SBP_aft
```{r warning=FALSE,message=FALSE}
checks <- c("Original","No Infl","No dysf/drugs","No Cov","All in","ML","Rand slope","logTransf",
            "confounders_aft","position","children","No flagBP","No flagTime","No careless","WE","WC","WHLSM retro")

# main effect of WHLSM.mc
predictors <- c("gender","age.gmc","BMI.gmc","WHLSM.cm.gmc","WHLSM.mc") # predictors
r <- "SBP_aft" # response variable
p <- cbind(check=checks,
      rbind(glmerAn(data=cleanBP_aft,resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # original
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft[!cleanBP_aft$ID%in%c("S096","S082"),], # without influential
                    resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft[cleanBP_aft$sleep_dysf=="No" & # without participants meeting exclusion criteria
                                       cleanBP_aft$psy_drugs=="No" & cleanBP_aft$psy_drugs=="No",], 
                    resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=c("WHLSM.mc"), # without covariates
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft_full,resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # full sample
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # maximum likelihood
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc",REML=FALSE),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # random slope
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc",ran.eff="(WHLSM.mc|ID)"),
            glmerAn(data=cleanBP_aft,resp="log(SBP_aft)",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # log-transf
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=c(predictors[1:3],"confounders_aft", # adding confounders_aft
                                                      predictors[4:length(predictors)]), 
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=c(predictors[1:3],"position", # adding position
                                                      predictors[4:length(predictors)]), 
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=c(predictors[1:3],"children", # adding children
                                                      predictors[4:length(predictors)]), 
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft[cleanBP_aft$flagBP_aft==FALSE,], # without flagged BP
                    resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft[cleanBP_aft$flagTime==FALSE,], # without flagged times
                    resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft[cleanBP_aft$careless==FALSE,], # without careless participant
                    resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=gsub("WHLSM.mc","WE.mc",predictors), 
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WE.mc",key.model="WE.mc"), # working excess
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=gsub("WHLSM.mc","WC.mc",predictors), 
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WC.mc",key.model="WC.mc"), # working compulsively
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=gsub("WHLSM.cm.gmc","WHLSM.retro.gmc",predictors), # WHLSM retro
                    mComp.baseline="WHLSM.retro.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc")))
kable(p)
```

<br>

#### DBP_aft
```{r warning=FALSE,message=FALSE}
checks <- c("Original","No Infl","No dysf/drugs","No Cov","All in","ML","Rand slope","logTransf",
            "confounders_aft","position","children","No flagBP","No flagTime","No careless","WE","WC","WHLSM retro")

# main effect of WHLSM.mc
predictors <- c("gender","age.gmc","BMI.gmc","WHLSM.cm.gmc","WHLSM.mc") # predictors
r <- "DBP_aft" # response variable
p <- cbind(check=checks,
      rbind(glmerAn(data=cleanBP_aft,resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # original
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft[!cleanBP_aft$ID%in%c("S082"),], # without influential
                    resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft[cleanBP_aft$sleep_dysf=="No" & # without participants meeting exclusion criteria
                                       cleanBP_aft$psy_drugs=="No" & cleanBP_aft$psy_drugs=="No",], 
                    resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=c("WHLSM.mc"), # without covariates
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft_full,resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # full sample
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # maximum likelihood
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc",REML=FALSE),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # random slope
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc",ran.eff="(WHLSM.mc|ID)"),
            glmerAn(data=cleanBP_aft,resp="log(SBP_aft)",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # log-transf
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=c(predictors[1:3],"confounders_aft", # adding confounders_aft
                                                      predictors[4:length(predictors)]), 
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=c(predictors[1:3],"position", # adding position
                                                      predictors[4:length(predictors)]), 
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=c(predictors[1:3],"children", # adding children
                                                      predictors[4:length(predictors)]), 
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft[cleanBP_aft$flagBP_aft==FALSE,], # without flagged BP
                    resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft[cleanBP_aft$flagTime==FALSE,], # without flagged times
                    resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft[cleanBP_aft$careless==FALSE,], # without careless
                    resp=r,fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=gsub("WHLSM.mc","WE.mc",predictors), 
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WE.mc",key.model="WE.mc"), # working excess
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=gsub("WHLSM.mc","WC.mc",predictors), 
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WC.mc",key.model="WC.mc"), # working compulsively
            glmerAn(data=cleanBP_aft,resp=r,fix.eff=gsub("WHLSM.cm.gmc","WHLSM.retro.gmc",predictors), 
                    mComp.baseline="WHLSM.retro.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc")))
kable(p)
```

<br>

### 4.1.2. Evening BP {.tabset .tabset-fade .tabset-pills}

For evening blood pressure, we implement the following robustness checks:

1. `No Infl`: we remove influential participants

2. `No dysf/drugs`: we remove all participants reporting sleep dysfunctions, hormonal or psychoactive medications, in addition to those meeting exclusion criteria for blood pressure

3. `No Cov`: we remove all covariates, that is we only include `WHLSM.mc` and its interactions as model predictors

4. `All in`: we include all complete observations from all participants, including those meeting the exclusion criteria for compliance and blood pressure

5. `ML`: we refit the models by using the Maximum Likelihood estimator, rather than the Restricted Maximum Likelihood

6. `Rand slope`: we include the random slope for `WHLSM.mc` 

7. `logTransf`: we log-transform the response variable values before fitting the models

8. `confounders_eve`: we include potentially confounding factors for blood pressure (e.g., smoking, physical activity) reported in the afternoon as an additional control variable

9. `position`: we include job position (Employee/Project vs. Manager/(Self-)Employer) as an additional control variable

10. `children`: we include the number of children as an additional control variable

11. `No flagBP`: we exclude all observations that were reprocessed due to extreme BP values (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html))

10. `No flagTime`: we exclude all observations that were flagged due to their associated timing (e.g., morning BP recorded in the afternoon) (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html))

12. `No careless`: we exclude one participant `S137` flagged as potentially careless (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html))

13. `day1`: we include recording `day` as a further covariate (i.e., 1 = first day, 2 = any other day). In all cases, the **results are consistent** with those reported in the main analyses, showing no substantial contribution and main effect of state `WHLSM.mc`.

14. `WE`: we replace the predictor term for state workaholism with the composite score at the working excessively dimension

15. `WC`: we replace the predictor term for state workaholism with the composite score at the working excessively dimension

16. `WHLSM retro`: we replace the predictor term for trait workaholism with the composite score at the retrospective version of the DUWAS included in the preliminary questionnaire.

```{r warning=FALSE,message=FALSE}
# setting robustness checks
checks <- c("Original","No Infl","No dysf/drugs","No Cov","All in","ML","Rand slope","logTransf",
            "confounders_eve","position","children","No flagBP","No flagTime","No careless","day1",
            "WE","WC","WHLSM retro")

# creating categorical variable day1 (i.e., first day vs. all other days)
cleanBP_eve$day1 <- 0 
cleanBP_eve[cleanBP_eve$day==1,"day1"] <- 1
cleanBP_eve$day1 <- as.factor(cleanBP_eve$day1)
```

<br>

In all cases, the **results are consistent** with those reported in the main analyses, showing no substantial contribution or main effect of state `WHLSM.mc` (only substantial in a few cases for `DBP_eve`) and no substantial interactions with psychological detachment.

#### MAIN EFFECT {.tabset .tabset-fade .tabset-pills}

##### SBP_eve
```{r warning=FALSE,message=FALSE}
predictors <- c("gender","age.gmc","BMI.gmc","PD.mc","WHLSM.cm.gmc","WHLSM.mc") # predictors
r <- "SBP_eve" # response variable
key <- "WHLSM.mc" # key model and key predictor
bsl <- "WHLSM.cm.gmc" # baseline model
p <- cbind(check=checks,
      rbind(glmerAn(data=cleanBP_eve,resp=r,fix.eff=predictors,mComp.baseline=bsl, # original
                    key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[!cleanBP_eve$ID%in%c("S082","S096"),], # without influential
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$sleep_dysf=="No" & # without participants meeting exclusion criteria
                                       cleanBP_eve$psy_drugs=="No" & cleanBP_eve$psy_drugs=="No",], 
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c("WHLSM.mc"), # without covariates
                    key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve_full,resp=r,fix.eff=predictors,mComp.baseline=bsl, # full sample
                    key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=predictors,mComp.baseline=bsl, # maximum likelihood
                    key.predictor=key,key.model=key,REML=FALSE),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=predictors,mComp.baseline=bsl, # random slope (SINGULAR FIT)
                    key.predictor=key,key.model=key,ran.eff="(WHLSM.mc|ID)"),
            glmerAn(data=cleanBP_eve,resp="log(SBP_eve)",fix.eff=predictors,mComp.baseline=bsl, # log-transf
                    key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:5],"confounders_eve", # adding confounders_eve
              predictors[6:length(predictors)]),mComp.baseline="confounders_eve",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:5],"position", # adding position
              predictors[6:length(predictors)]),mComp.baseline="position",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:5],"children", # adding children
              predictors[6:length(predictors)]),mComp.baseline="children",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$flagBP_eve==FALSE,], # without flagged BP
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$flagTime==FALSE,], # without flagged times
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$careless==FALSE,], # without careless
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:5],"day1",predictors[6:length(predictors)]), # adding day
                    mComp.baseline="day1",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=gsub("WHLSM.mc","WE.mc",predictors), # working excessively
                    mComp.baseline=bsl,key.predictor="WE.mc",key.model="WE.mc"),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=gsub("WHLSM.mc","WC.mc",predictors), # working compulsively
                    mComp.baseline=bsl,key.predictor="WC.mc",key.model="WC.mc"),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=gsub("WHLSM.cm.gmc","WHLSM.retro.gmc",predictors), # WHLSM retro
                    mComp.baseline="WHLSM.retro.gmc",key.predictor=key,key.model=key)))
kable(p)
```

<br>

##### DBP_eve
```{r warning=FALSE,message=FALSE}
r <- "DBP_eve" # response variable
p <- cbind(check=checks,
      rbind(glmerAn(data=cleanBP_eve,resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key), # original
            glmerAn(data=cleanBP_eve[!cleanBP_eve$ID%in%c("S082","S080"),], # without influential
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$sleep_dysf=="No" & # without participants meeting exclusion criteria
                                       cleanBP_eve$psy_drugs=="No" & cleanBP_eve$psy_drugs=="No",], 
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c("WHLSM.mc"),key.predictor=key,key.model=key), # without covariates
            glmerAn(data=cleanBP_eve_full,resp=r,fix.eff=predictors,mComp.baseline=bsl, # full sample
                    key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=predictors,mComp.baseline=bsl, # maximum likelihood
                    key.predictor=key,key.model=key,REML=FALSE),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=predictors,mComp.baseline=bsl, # random slope
                    key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp="log(DBP_eve)",fix.eff=predictors,mComp.baseline=bsl, # Gamma log
                    key.predictor=key,key.model=key,family="gamma",link="log"),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:5],"confounders_eve", # adding confounders_eve
              predictors[6:length(predictors)]),mComp.baseline="confounders_eve",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:5],"position", # adding position
              predictors[6:length(predictors)]),mComp.baseline="position",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:5],"children", # adding children
              predictors[6:length(predictors)]),mComp.baseline="children",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$flagBP_eve==FALSE,], # without flagged BP
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$flagTime==FALSE,], # without flagged times
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$careless==FALSE,], # without careless participants
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:5],"day1",predictors[6:length(predictors)]), # adding day
                    mComp.baseline="day1",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=gsub("WHLSM.mc","WE.mc",predictors), # working excessively
                    mComp.baseline=bsl,key.predictor="WE.mc",key.model="WE.mc"),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=gsub("WHLSM.mc","WC.mc",predictors), # working compulsively
                    mComp.baseline=bsl,key.predictor="WC.mc",key.model="WC.mc"),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=gsub("WHLSM.cm.gmc","WHLSM.retro.gmc",predictors), 
                    mComp.baseline="WHLSM.retro.gmc",key.predictor=key,key.model=key)))
kable(p)
```

<br>

#### INTERACTION {.tabset .tabset-fade .tabset-pills}

##### SBP_eve
```{r warning=FALSE,message=FALSE}
# interaction with RDet.mc
r <- "SBP_eve"
predictors <- c(predictors,"PD.mc:WHLSM.mc") # predictors
key <- "PD.mc:WHLSM.mc" # key model and key predictor
bsl <- "WHLSM.mc" # baseline model
p <- cbind(check=checks,
      rbind(glmerAn(data=cleanBP_eve,resp=r,fix.eff=predictors,mComp.baseline=bsl, # original
                    key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[!cleanBP_eve$ID%in%c("S096","S082"),], # without influential
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve_full,resp=r,fix.eff=predictors,mComp.baseline=bsl, # full sample
                    key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$sleep_dysf=="No" & # without participants meeting exclusion criteria
                                       cleanBP_eve$psy_drugs=="No" & cleanBP_eve$psy_drugs=="No",], 
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c("PD.mc","WHLSM.mc","PD.mc:WHLSM.mc"), # without covariates
                    mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=predictors,mComp.baseline=bsl, # maximum likelihood
                    key.predictor=key,key.model=key,REML=FALSE),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=predictors,mComp.baseline=bsl, # random slope (SINGULAR FIT)
                    key.predictor=key,key.model=key,ran.eff="(WHLSM.mc|ID)"),
            glmerAn(data=cleanBP_eve,resp="log(SBP_eve)",fix.eff=predictors,mComp.baseline=bsl, # log-transf
                    key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:6],"confounders_eve", # adding confounders_eve
                                                      predictors[7:length(predictors)]),
                    mComp.baseline="confounders_eve",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:6],"position", # adding position
                                                     predictors[7:length(predictors)]),
                    mComp.baseline="position",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:6],"children", # adding children
                                                     predictors[7:length(predictors)]),
                    mComp.baseline="children",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$flagBP_eve==FALSE,], # without flagged BP
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$flagTime==FALSE,], # without flagged times
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$careless==FALSE,], # without careless participant
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:6],"day1",predictors[7:length(predictors)]), # adding day
                    mComp.baseline="day1",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=gsub("WHLSM.mc","WE.mc",predictors), # working excessively
                    mComp.baseline="WE.mc",key.predictor="PD.mc:WE.mc",key.model="PD.mc:WE.mc"),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=gsub("WHLSM.mc","WC.mc",predictors), # working compulsively
                    mComp.baseline="WC.mc",key.predictor="PD.mc:WC.mc",key.model="PD.mc:WC.mc"),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=gsub("WHLSM.cm.gmc","WHLSM.retro.gmc",predictors),  # WHLSM.retro
                    mComp.baseline=bsl,key.predictor=key,key.model=key)))
kable(p)
```

<br>

##### DBP_eve
```{r warning=FALSE,message=FALSE}
r <- "DBP_eve"
p <- cbind(check=checks,
      rbind(glmerAn(data=cleanBP_eve,resp=r,fix.eff=predictors,mComp.baseline=bsl, # original
                    key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[!cleanBP_eve$ID%in%c("S096","S080"),], # without influential
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$sleep_dysf=="No" & # without participants meeting exclusion criteria (SINGULAR FIT)
                                       cleanBP_eve$psy_drugs=="No" & cleanBP_eve$psy_drugs=="No",], 
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c("PD.mc","WHLSM.mc","PD.mc:WHLSM.mc"), # without covariates
                    mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve_full,resp=r,fix.eff=predictors,mComp.baseline=bsl, # full sample
                    key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=predictors,mComp.baseline=bsl, # maximum likelihood
                    key.predictor=key,key.model=key,REML=FALSE),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=predictors,mComp.baseline=bsl, # random slope
                    key.predictor=key,key.model=key,ran.eff="(WHLSM.mc|ID)"),
            glmerAn(data=cleanBP_eve,resp="DBP_eve",fix.eff=predictors,mComp.baseline=bsl, # Gamma log
                    key.predictor=key,key.model=key,family="gamma",link="log"),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:6],"confounders_eve", # adding confounders_eve
                                                      predictors[7:length(predictors)]),
                    mComp.baseline="confounders_eve",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:6],"position", # adding position
                                                      predictors[7:length(predictors)]),
                    mComp.baseline="position",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:6],"children", # adding children
                                                      predictors[7:length(predictors)]),
                    mComp.baseline="children",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$flagBP_eve==FALSE,], # without flagged BP
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$flagTime==FALSE,], # without flagged times
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve[cleanBP_eve$careless==FALSE,], # without careless
                    resp=r,fix.eff=predictors,mComp.baseline=bsl,key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=c(predictors[1:6],"day1",predictors[7:length(predictors)]), # adding day
                    mComp.baseline="day1",key.predictor=key,key.model=key),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=gsub("WHLSM.mc","WE.mc",predictors), # working excessively
                    mComp.baseline="WE.mc",key.predictor="PD.mc:WE.mc",key.model="PD.mc:WE.mc"),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=gsub("WHLSM.mc","WC.mc",predictors), # working compulsively
                    mComp.baseline="WC.mc",key.predictor="PD.mc:WC.mc",key.model="PD.mc:WC.mc"),
            glmerAn(data=cleanBP_eve,resp=r,fix.eff=gsub("WHLSM.cm.gmc","WHLSM.retro.gmc",predictors), # WHLSM.retro
                    mComp.baseline=bsl,key.predictor=key,key.model=key)))
kable(p)
```

<br>

### 4.1.3. Mediations {.tabset .tabset-fade .tabset-pills}

For Afternoon-to-Evening mediations, we implement the following robustness checks:

1. `No Infl`: we remove all influential participants found for afternoon and evening BP

2. `No dysf/drugs`: we remove all participants reporting sleep dysfunctions, hormonal or psychoactive medications, in addition to those meeting exclusion criteria for blood pressure

3. `No Cov`: we remove all covariates, that is we only include `WHLSM.mc` and its interactions as model predictors

4. `All in`: we include all complete observations from all participants, including those meeting the exclusion criteria for compliance and blood pressure

5. `ML`: we refit the models by using the Maximum Likelihood estimator, rather than the Restricted Maximum Likelihood

6. `Rand slope`: we include the random slope for `WHLSM.mc`

7. `log-transf`: we log-transform blood pressure before fitting the models

8. `confounders`: we include potentially confounding factors for blood pressure (e.g., smoking, physical activity) reported in the afternoon or in the evening as an additional control variable

9. `position`: we include job position (Employee/Project vs. Manager/(Self-)Employer) as an additional control variable

10. `children`: we include the number of children as an additional control variable

11. `No flagBP`: we exclude all observations that were reprocessed due to extreme BP values either in the afternoon or in the evening (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html)); morning flagged cases are not considered to avoid loosing too many observations

12. `No flagTime`: we exclude all observations that were flagged due to their associated timing (e.g., morning BP recorded in the afternoon) (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html))

13. `No careless`: we exclude one participant `S137` flagged as potentially careless (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html))

14. `day1`: we include recording `day` as a further covariate (i.e., 1 = first day, 2 = any other day). In all cases, the **results are consistent** with those reported in the main analyses, showing no substantial contribution and main effect of state `WHLSM.mc`.

15. `WE`: we replace the predictor term for state workaholism with the composite score at the working excessively dimension

16. `WC`: we replace the predictor term for state workaholism with the composite score at the working excessively dimension

17. `WHLSM retro`: we replace the predictor term for trait workaholism with the composite score at the retrospective version of the DUWAS included in the preliminary questionnaire.

```{r warning=FALSE,message=FALSE}
# setting robustness checks
checks <- c("Original","No Infl","No dysf/drugs","No Cov","All in","ML","Rand slope","log-transf",
            "confounders","position","children","No flagBP","No flagTime","No careless","day1",
            "WE","WC","WHLSM.retro")

# recoding variables
cleanBP_med_eve$conf <- FALSE # summary of afternoon and evening confounders
cleanBP_med_eve[cleanBP_med_eve$confounders_aft==TRUE | cleanBP_med_eve$confounders_eve==TRUE,"conf"] <- TRUE
summary(cleanBP_med_eve$conf)
cleanBP_med_eve$flagBP <- FALSE # summary of afternoon and evening flagBP
cleanBP_med_eve[cleanBP_med_eve$flagBP_aft==TRUE | cleanBP_med_eve$flagBP_eve==TRUE,"flagBP"] <- TRUE
summary(cleanBP_med_eve$flagBP)
cleanBP_med_eve$day1 <- 0 # creating categorical variable day1 (i.e., first day vs. all other days)
cleanBP_med_eve[cleanBP_med_eve$day==1,"day1"] <- 1
cleanBP_med_eve$day1 <- as.factor(cleanBP_med_eve$day1)
summary(cleanBP_med_eve$day1)
```

<br>

In all cases, the **results for `SBP` are consistent** with those reported in the main analyses, showing significant indirect but not direct relationship between state `WHLSM.mc` and `SBP_eve`. **Most results for `DBP` are consistent** as well, but the **indirect relationship is reduced in one case**, i.e., with the removal of participants reporting sleep dysfunctions, hormonal, or psychoactive medications. Similarly, the direct relationship becomes significant with the inclusion of `day1` as a covariate. Whereas these findings question the generalizability of such relationship, the high number of consistent robustness checks provides some evidence that the relationship is observable in our sample.

####  SBP_eve
```{r warning=FALSE,message=FALSE}
predictors <- c("gender","age.gmc","BMI.gmc","PD.mc","WHLSM.cm.gmc","WHLSM.mc") # predictors
r <- "SBP_eve" # response variable
t <- "WHLSM.mc" # key model and key predictor
m <- "SBP_aft.mc"
p <- cbind(check=checks,
      rbind(glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=predictors), # original
            glmerMed(data=cleanBP_med_eve[!cleanBP_med_eve$ID%in%c("S082","S096"),], # without influential cases
                    resp=r,treat=t,med=m,fix.eff=predictors),
            glmerMed(data=cleanBP_med_eve[cleanBP_med_eve$sleep_dysf=="No" & # without participants meeting exclusion criteria
                                       cleanBP_med_eve$psy_drugs=="No" & cleanBP_med_eve$psy_drugs=="No",], 
                    resp=r,treat=t,med=m,fix.eff=predictors),
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=c("WHLSM.mc"),noCov=TRUE), # w/o covariates
            glmerMed(data=cleanBP_med_eve_full,resp=r,treat=t,med=m,fix.eff=predictors), # full sample
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=predictors,REML=FALSE), # maximum likelihood
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=predictors, # random slope (singular fit)
                     ran.eff="(WHLSM.mc|ID)"), 
            glmerMed(data=cleanBP_med_eve,resp="log(SBP_eve)",treat=t,med=m,fix.eff=predictors), # log transformation
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=c(predictors[1:5],"conf", # adding confounders
              predictors[6:length(predictors)])),
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=c(predictors[1:5],"position", # adding position
              predictors[6:length(predictors)])),
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=c(predictors[1:5],"children", # adding children
              predictors[6:length(predictors)])),
            glmerMed(data=cleanBP_med_eve[cleanBP_med_eve$flagBP==FALSE,], # without flagged BP cases
                     resp=r,treat=t,med=m,fix.eff=predictors),
            glmerMed(data=cleanBP_med_eve[cleanBP_med_eve$flagTime==FALSE,], # without flagged times
                     resp=r,treat=t,med=m,fix.eff=predictors),
            glmerMed(data=cleanBP_med_eve[cleanBP_med_eve$careless==FALSE,], # without careless participants
                     resp=r,treat=t,med=m,fix.eff=predictors),
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=c(predictors[1:5],"day1", # adding day
              predictors[6:length(predictors)])),
            glmerMed(data=cleanBP_med_eve,resp=r,treat="WE.mc",med=m,
                     fix.eff=gsub("WHLSM.mc","WE.mc",predictors)), # working excessively
            glmerMed(data=cleanBP_med_eve,resp=r,treat="WC.mc",med=m,
                     fix.eff=gsub("WHLSM.mc","WC.mc",predictors)), # working compulsively
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,
                     fix.eff=gsub("WHLSM.cm.gmc","WHLSM.retro",predictors)))) # WHLSM retro
kable(p)
```

<br>

#### DBP_eve
```{r warning=FALSE,message=FALSE}
r <- "DBP_eve" # response variable
p <- cbind(check=checks,
      rbind(glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=predictors), # original
            glmerMed(data=cleanBP_med_eve[!cleanBP_med_eve$ID%in%c("S082","S096"),], # without influential cases
                    resp=r,treat=t,med=m,fix.eff=predictors),
            glmerMed(data=cleanBP_med_eve[cleanBP_med_eve$sleep_dysf=="No" & # without participants meeting exclusion criteria
                                       cleanBP_med_eve$psy_drugs=="No" & cleanBP_med_eve$psy_drugs=="No",], 
                    resp=r,treat=t,med=m,fix.eff=predictors),
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=c("WHLSM.mc"),noCov=TRUE), # w/o covariates
            glmerMed(data=cleanBP_med_eve_full,resp=r,treat=t,med=m,fix.eff=predictors), # full sample
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=predictors,REML=FALSE), # maximum likelihood
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=predictors, # random slope (singular fit)
                     ran.eff="(WHLSM.mc|ID)"), 
            glmerMed(data=cleanBP_med_eve,resp="log(DBP_eve)",treat=t,med=m,fix.eff=predictors), # log-transformation
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=c(predictors[1:5],"conf", # adding confounders
              predictors[6:length(predictors)])),
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=c(predictors[1:5],"position", # adding position
              predictors[6:length(predictors)])),
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=c(predictors[1:5],"children", # adding children
              predictors[6:length(predictors)])),
            glmerMed(data=cleanBP_med_eve[cleanBP_med_eve$flagBP==FALSE,], # without flagged BP cases
                     resp=r,treat=t,med=m,fix.eff=predictors),
            glmerMed(data=cleanBP_med_eve[cleanBP_med_eve$flagTime==FALSE,], # without flagged times
                     resp=r,treat=t,med=m,fix.eff=predictors),
            glmerMed(data=cleanBP_med_eve[cleanBP_med_eve$careless==FALSE,], # without careless participants
                     resp=r,treat=t,med=m,fix.eff=predictors),
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,fix.eff=c(predictors[1:5],"day1", # adding day
              predictors[6:length(predictors)])),
            glmerMed(data=cleanBP_med_eve,resp=r,treat="WE.mc",med=m,
                     fix.eff=gsub("WHLSM.mc","WE.mc",predictors)), # working excessively
            glmerMed(data=cleanBP_med_eve,resp=r,treat="WC.mc",med=m,
                     fix.eff=gsub("WHLSM.mc","WC.mc",predictors)), # working compulsively
            glmerMed(data=cleanBP_med_eve,resp=r,treat=t,med=m,
                     fix.eff=gsub("WHLSM.cm.gmc","WHLSM.retro.gmc",predictors)))) # WHLSM retro
kable(p)
```

<br>

## 4.2. Emotional Exhaustion  {.tabset .tabset-fade .tabset-pills}

For emotional exhaustion, we implement the following robustness checks:

1. `No Infl`: we remove influential participants

2. `No Cov`: we remove all covariates, that is we only include `WHLSM.mc` and its interactions as model predictors

3. `All in`: we include all complete observations from all participants, including those meeting the exclusion criteria for compliance and blood pressure

4. `ML`: we refit the models by using the Maximum Likelihood estimator, rather than the Restricted Maximum Likelihood

5. `Rand slope`: we include the random slope for `WHLSM.mc` 

6. `Gamma-log`: we refit the models using the Gamma family with the logarithmic link function

7. `logNorm`: we refit the models with using log-normal GLM

8. `position`: we include job position (Employee/Project vs. Manager/(Self-)Employer) as an additional control variable

9. `children`: we include the number of children as an additional control variable

10. `No flagTime`: we exclude all observations that were flagged due to their associated timing (e.g., morning BP recorded in the afternoon) (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html))

11. `No careless`: we exclude one participant `S137` flagged as potentially careless (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html)).

12. `day`: we include `day` as a further continuous covariate (i.e., 1 = first day, 2 = second day, etc.) 

13. `WE`: we replace the predictor term for state workaholism with the composite score at the working excessively dimension

14. `WC`: we replace the predictor term for state workaholism with the composite score at the working excessively dimension

15. `WHLSM retro`: we replace the predictor term for trait workaholism with the composite score at the retrospective version of the DUWAS included in the preliminary questionnaire.

```{r warning=FALSE,message=FALSE}
checks <- c("Original","No Infl","No Cov","All in","ML","Rand slope","Gamma-log","logNorm",
            "position","children","No flagTime","No careless","day","WE","WC","WHLSM retro")
```

<br>

In all cases, the **results are consistent** with those reported in the main analyses, showing substantial contribution and main effect of state `WHLSM.mc`, but with no substantial interaction with `PD.mc` (only significant when using the log-normal distribution). Thus, we interpret these findings as a sign of the **consistency of the estimated relationship** between state `WHLSM.mc` and `EE`.

### MAIN EFFECT
```{r warning=FALSE,message=FALSE}
# main effect of WHLSM.mc
predictors <- c("gender","PD.mc","WHLSM.cm.gmc","WHLSM.mc")
p <- cbind(check=checks,
      rbind(glmerAn(data=cleanEE,resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # original
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanEE[!cleanEE$ID%in%c("S049"),], # without influential
                    resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=c("WHLSM.mc"), # without covariates
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanEE_full,resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # full sample
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # maximum likelihood
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc",REML=FALSE),
            glmerAn(data=cleanEE,resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # random slope
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc",ran.eff="(WHLSM.mc|ID)"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # Gamma-log family
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc",family="gamma",link="log"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # log-normal family
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc",link="log"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=c(predictors[1],"position", # adding position
                                                      predictors[2:length(predictors)]),
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=c(predictors[1],"children", # adding children
                                                      predictors[2:length(predictors)]),
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanEE[cleanEE$flagTime==FALSE,],resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", 
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"), # without flagged times
            glmerAn(data=cleanEE[cleanEE$careless==FALSE,],resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", 
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"), # without careless participants
            glmerAn(data=cleanEE,resp="EE",fix.eff=c(predictors[1:3],"day",predictors[4:length(predictors)]),
                    mComp.baseline="day",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=gsub("WHLSM.mc","WE.mc",predictors),
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WE.mc",key.model="WE.mc"), # working excessively
            glmerAn(data=cleanEE,resp="EE",fix.eff=gsub("WHLSM.mc","WC.mc",predictors),
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WC.mc",key.model="WC.mc"), # working compulsively
            glmerAn(data=cleanEE,resp="EE",fix.eff=gsub("WHLSM.cm.gmc","WHLSM.retro.gmc",predictors),
                    mComp.baseline="WHLSM.retro.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"))) # WHLSM retro
kable(p)
```

<br>

### INTERACTION
```{r warning=FALSE,message=FALSE}
predictors <- c(predictors,"PD.mc:WHLSM.mc")
p <- cbind(check=checks,
      rbind(glmerAn(data=cleanEE,resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.mc", # original
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"),
            glmerAn(data=cleanEE[!cleanEE$ID%in%c("S049"),], # without influential cases
                    resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.mc",
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=c("PD.mc","WHLSM.mc","PD.mc:WHLSM.mc"), # without covariates
                    mComp.baseline="WHLSM.mc", key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"),
            glmerAn(data=cleanEE_full,resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.mc", # full sample
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.mc", # maximum likelihood
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc",REML=FALSE),
            glmerAn(data=cleanEE,resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.mc", # random slope
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc",ran.eff="(WHLSM.mc|ID)"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.mc", # gamma-log family
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc",family="gamma",link="log"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.mc", # log-normal family
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc",link="log"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=c(predictors[1],"position", # adding position
                                                      predictors[2:length(predictors)]),
                    mComp.baseline="WHLSM.mc",key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"),
            glmerAn(data=cleanEE,resp="EE",fix.eff=c(predictors[1],"children", # adding children
                                                      predictors[2:length(predictors)]),
                    mComp.baseline="WHLSM.mc",key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"),
            glmerAn(data=cleanEE[cleanEE$flagTime==FALSE,],resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.mc",
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"), # withoug flagged times
            glmerAn(data=cleanEE[cleanEE$careless==FALSE,],resp="EE",fix.eff=predictors,mComp.baseline="WHLSM.mc",
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"), # without careless participant
            glmerAn(data=cleanEE,resp="EE",fix.eff=c(predictors[1:3],"day",predictors[4:length(predictors)]),
                    mComp.baseline="WHLSM.mc",key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"), # day as covariate
            glmerAn(data=cleanEE,resp="EE",fix.eff=gsub("WHLSM.mc","WE.mc",predictors),
                    mComp.baseline="WE.mc",key.predictor="PD.mc:WE.mc",key.model="PD.mc:WE.mc"), # working excessively
            glmerAn(data=cleanEE,resp="EE",fix.eff=gsub("WHLSM.mc","WC.mc",predictors),
                    mComp.baseline="WC.mc",key.predictor="PD.mc:WC.mc",key.model="PD.mc:WC.mc"), # working compulsively
            glmerAn(data=cleanEE,resp="EE",fix.eff=gsub("WHLSM.cm.gmc","WHLSM.retro.gmc",predictors),
                    mComp.baseline="WHLSM.mc",key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"))) # WHLSM retro
kable(p)
```

<br>

## 4.3. Sleep disturbances  {.tabset .tabset-fade .tabset-pills}

For sleep disturbances, we implement the following robustness checks:

1. `No Infl`: we remove influential participants

2. `No sleepDysf`: we remove all participants reporting sleep dysfunctions

3. `No Cov`: we remove all covariates, that is we only include `WHLSM.mc` and its interactions as model predictors

4. `All in`: we include all complete observations from all participants, including those meeting the exclusion criteria for compliance and blood pressure

5. `ML`: we refit the models by using the Maximum Likelihood estimator, rather than the Restricted Maximum Likelihood

6. `Rand slope`: we include the random slope for `WHLSM.mc` 

7. `logNorm`: we refit the models with using log-normal GLM

8. `position`: we include job position (Employee/Project vs. Manager/(Self-)Employer) as an additional control variable

9. `children`: we include the number of children as an additional control variable

10. `No flagTime`: we exclude all observations that were flagged due to their associated timing (e.g., morning BP recorded in the afternoon) (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html))

11. `No careless`: we exclude one participant `S137` flagged as potentially careless (see [Supplementary Material S3](https://Luca-Menghini.github.io/the-daily-costs-of-workaholism/S3_preProcessing/S3_data-processing-code-and-output.html))

12. `WE`: we replace the predictor term for state workaholism with the composite score at the working excessively dimension

13. `WC`: we replace the predictor term for state workaholism with the composite score at the working excessively dimension

14. `WHLSM retro`: we replace the predictor term for trait workaholism with the composite score at the retrospective version of the DUWAS included in the preliminary questionnaire

```{r warning=FALSE,message=FALSE}
checks <- c("Original","No Infl","No sleepDysf","No Cov","All in","ML","Rand slope","logNorm",
            "position","children","No flagTime","No careless","WE","WC","WHLSM retro")
```

<br>

In all but two cases (i.e., only the interaction but not the main effect of state workaholism is substantial when including the random slope and when using the working compulsively dimension rather than the total state workaholism score), the **results are consistent** with those reported in the main analyses, showing substantial main effect of state `WHLSM.mc` and interaction. We interpret these findings as a sign of the **consistency of the estimated interactions** between `WHLSM.mc` and `PD.mc` for `SD`.

### MAIN EFFECT
```{r warning=FALSE,message=FALSE}
# main effect of WHLSM.mc
predictors <- c("gender","PD.mc","WHLSM.cm.gmc","WHLSM.mc")
p <- cbind(check=checks,
      rbind(glmerAn(data=cleanSD,resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # original
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanSD[!cleanSD$ID%in%c("S132","S049","S079","S002"),], # without influential
                    resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanSD[clean$sleep_dysf!="Yes",], # without participants with sleep dysf
                    resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanSD,resp="SD",fix.eff=c("WHLSM.mc"), # without covariates
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanSD_full,resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # full sample
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanSD,resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # maximum likelihood
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc",REML=FALSE),
            glmerAn(data=cleanSD,resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # random slope
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc",ran.eff="(WHLSM.mc|ID)"),
            glmerAn(data=cleanSD,resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", # log-normal family
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc",link="log"),
            glmerAn(data=cleanSD,resp="SD",fix.eff=c(predictors[1],"position", # adding position
                                                      predictors[2:length(predictors)]),
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanSD,resp="SD",fix.eff=c(predictors[1],"children", # adding children
                                                      predictors[2:length(predictors)]),
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanSD[cleanSD$flagTime==FALSE,],resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.cm.gmc", 
                    key.predictor="WHLSM.mc",key.model="WHLSM.mc"), # without flagged times
            glmerAn(data=cleanSD[cleanSD$careless==FALSE,],resp="SD",fix.eff=predictors,  # without careless
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"),
            glmerAn(data=cleanSD,resp="SD",fix.eff=gsub("WHLSM.mc","WE.mc",predictors),
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WE.mc",key.model="WE.mc"), # working excessively
            glmerAn(data=cleanSD,resp="SD",fix.eff=gsub("WHLSM.mc","WC.mc",predictors),
                    mComp.baseline="WHLSM.cm.gmc",key.predictor="WC.mc",key.model="WC.mc"), # working compulsively
            glmerAn(data=cleanSD,resp="SD",fix.eff=gsub("WHLSM.cm.gmc","WHLSM.retro.gmc",predictors),
                    mComp.baseline="WHLSM.retro.gmc",key.predictor="WHLSM.mc",key.model="WHLSM.mc"))) # WHLSM retro
kable(p)
```

<br>

### INTERACTION
```{r warning=FALSE,message=FALSE}
predictors <- c(predictors,"PD.mc:WHLSM.mc")
p <- cbind(check=checks,
      rbind(glmerAn(data=cleanSD,resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.mc", # original
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"),
            glmerAn(data=cleanSD[!cleanSD$ID%in%c("S132","S049","S079","S002"),], # without influential cases
                    resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.mc",
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"),
            glmerAn(data=cleanSD[clean$sleep_dysf!="Yes",], # without participants with sleep dysfunctions
                    resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.mc",
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"), 
            glmerAn(data=cleanSD,resp="SD",fix.eff=c("PD.mc","WHLSM.mc","PD.mc:WHLSM.mc"), # without covariates
                    mComp.baseline="WHLSM.mc", key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"),
            glmerAn(data=cleanSD_full,resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.mc", # full sample
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"),
            glmerAn(data=cleanSD,resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.mc", # maximum likelihood
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc",REML=FALSE),
            glmerAn(data=cleanSD,resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.mc", # random slope
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc",ran.eff="(WHLSM.mc|ID)"),
            glmerAn(data=cleanSD,resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.mc", # log-normal family
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc",link="log"),
            glmerAn(data=cleanSD,resp="SD",fix.eff=c(predictors[1],"position", # adding position
                                                      predictors[2:length(predictors)]),
                    mComp.baseline="WHLSM.mc",key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"),
            glmerAn(data=cleanSD,resp="SD",fix.eff=c(predictors[1],"children", # adding children
                                                      predictors[2:length(predictors)]),
                    mComp.baseline="WHLSM.mc",key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"),
            glmerAn(data=cleanSD[cleanSD$flagTime==FALSE,],resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.mc",
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"), # withoug flagged times
            glmerAn(data=cleanSD[cleanSD$careless==FALSE,],resp="SD",fix.eff=predictors,mComp.baseline="WHLSM.mc",
                    key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"), # without careless participants
            
            glmerAn(data=cleanSD,resp="SD",fix.eff=gsub("WHLSM.mc","WE.mc",predictors),
                    mComp.baseline="WE.mc",key.predictor="PD.mc:WE.mc",key.model="PD.mc:WE.mc"), # working excessively
            glmerAn(data=cleanSD,resp="SD",fix.eff=gsub("WHLSM.mc","WC.mc",predictors),
                    mComp.baseline="WC.mc",key.predictor="PD.mc:WC.mc",key.model="PD.mc:WC.mc"), # working compulsively
            
            glmerAn(data=cleanSD,resp="SD",fix.eff=gsub("WHLSM.cm.gmc","WHLSM.retro.gmc",predictors),
                    mComp.baseline="WHLSM.mc",key.predictor="PD.mc:WHLSM.mc",key.model="PD.mc:WHLSM.mc"))) # WHLSM retro
kable(p)
```

<br>

# 5. Outputs

Here, we generate and save the regression tables reporting the results estimated by the selected models. For each model, we visualize the unstandardized coefficients (b), the standard error (SE), and the **95% bootstrap confidence intervals** computed with 10,000 iterations.
```{r warning=FALSE,message=FALSE,fig.width=5,fig.height=4}
NSIM = 10000

# coefficients afternoon BP
tab_model(m1_SBP_aft,m2_SBP_aft,m1_DBP_aft,m2_DBP_aft,
          dv.labels=paste0(rep(c("SBP_aft_","DBP_aft_"),each=2),c("baseline","WHLSM.mc")),
          show.icc=FALSE,show.p=FALSE,show.se=TRUE,show.r2=FALSE,collapse.se=TRUE,string.est="b (SE)")

# bootstrap CI SBP_aft
confint.merMod(m1_SBP_aft,parm=3:(length(fixef(m1_SBP_aft))+2),method="boot",nsim=NSIM) # M1
confint.merMod(m2_SBP_aft,parm=3:(length(fixef(m2_SBP_aft))+2),method="boot",nsim=NSIM) # M2

# bootstrap CI DBP_aft
confint.merMod(m1_DBP_aft,parm=5:(length(fixef(m1_SBP_aft))+2),method="boot",nsim=NSIM) # M1
confint.merMod(m2_DBP_aft,parm=5:(length(fixef(m2_SBP_aft))+2),method="boot",nsim=NSIM) # M2

# coefficients evening BP
tab_model(m1_SBP_eve,m2_SBP_eve,m3_SBP_eve,m1_DBP_eve,m2_DBP_eve,m3_DBP_eve,
          dv.labels=paste0(rep(c("SBP_eve_","DBP_eve_"),each=3),c("baseline","WHLSM.mc","interaction")),
          show.icc=FALSE,show.p=FALSE,show.se=TRUE,show.r2=FALSE,collapse.se=TRUE,string.est="b (SE)")

# bootstrap CI SBP_eve
confint.merMod(m1_SBP_eve,parm=3:(length(fixef(m1_SBP_eve))+2),method="boot",nsim=NSIM) # M1
confint.merMod(m2_SBP_eve,parm=3:(length(fixef(m2_SBP_eve))+2),method="boot",nsim=NSIM) # M2
confint.merMod(m3_SBP_eve,parm=3:(length(fixef(m3_SBP_eve))+2),method="boot",nsim=NSIM) # M3

# bootstrap CI DBP_eve
confint.merMod(m1_DBP_eve,parm=3:(length(fixef(m1_DBP_eve))+2),method="boot",nsim=NSIM) # M1
confint.merMod(m2_DBP_eve,parm=3:(length(fixef(m2_DBP_eve))+2),method="boot",nsim=NSIM) # M2
confint.merMod(m3_DBP_eve,parm=3:(length(fixef(m3_DBP_eve))+2),method="boot",nsim=NSIM) # M3

# coefficients EE and SD
tab_model(m1_EE,m2_EE,m3_EE,m1_SD,m2_SD,m3_SD,
          dv.labels=paste0(rep(c("EE_","SD_"),each=3),c("baseline","WHLSM.mc","interaction")),
          show.icc=FALSE,show.p=FALSE,show.se=TRUE,show.r2=FALSE,collapse.se=TRUE,string.est="b (SE)")

 # bootstrap CI EE 
confint.merMod(m1_EE,parm=3:(length(fixef(m1_EE))+2),method="boot",nsim=NSIM) # M1
confint.merMod(m2_EE,parm=3:(length(fixef(m2_EE))+2),method="boot",nsim=NSIM) # M2
confint.merMod(m3_EE,parm=3:(length(fixef(m3_EE))+2),method="boot",nsim=NSIM) # M3

# boostrap CI SD
confint.merMod(m1_SD,parm=3:(length(fixef(m1_SD))+2),method="boot",nsim=NSIM) # M1
confint.merMod(m2_SD,parm=3:(length(fixef(m2_SD))+2),method="boot",nsim=NSIM) # M2
confint.merMod(m3_SD,parm=3:(length(fixef(m3_SD))+2),method="boot",nsim=NSIM) # M3

# plotting interaction
library(ggplot2); library(gridExtra)
sd(cleanSD$PD.mc) # RDet: 1 SD = 1.36
p <- plot_model(m3_SD,type="pred",terms=c("WHLSM.mc","PD.mc [-1.36,1.36]"),colors="bw",
           alpha=0.4,legend.title="Psychological\ndetachment",axis.title=c("State workaholism","Sleep disturbances")) +
  scale_color_manual(labels=c("-1 SD","+1 SD"),values=c("black","#666666")) +
  scale_linetype_manual(labels=c("-1 SD","+1 SD"),values=c("solid","dashed")) +
  scale_fill_manual(labels=c("-1 SD","+1 SD"),values=c("black","#666666")) + ggtitle("") +
                    theme(text=element_text(size=15))
p
ggsave("RESULTS/Figure3.tiff",plot=p,dpi=300,width=5,height=4)
```

<br>

# References {#ref}

- Steegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016). Increasing transparency through a multiverse analysis. *Perspectives on Psychological Science, 11*(5), 702-712. https://doi.org/10.1177/1745691616658637

<br>

## R packages